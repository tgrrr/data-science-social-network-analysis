{
  "data": {
    "repository": {
      "ref": {
        "target": {
          "history": {
            "edges": [
              {
                "node": {
                  "messageHeadline": "Merge branch 'i2c/for-5.4' of git://git.kernel.org/pub/scm/linux/kern…",
                  "message": "Merge branch 'i2c/for-5.4' of git://git.kernel.org/pub/scm/linux/kernel/git/wsa/linux\n\nPull i2c updates from Wolfram Sang:\n\n - new driver for ICY, an Amiga Zorro card :)\n\n - axxia driver gained slave mode support, NXP driver gained ACPI\n\n - the slave EEPROM backend gained 16 bit address support\n\n - and lots of regular driver updates and reworks\n\n* 'i2c/for-5.4' of git://git.kernel.org/pub/scm/linux/kernel/git/wsa/linux: (52 commits)\n  i2c: tegra: Move suspend handling to NOIRQ phase\n  i2c: imx: ACPI support for NXP i2c controller\n  i2c: uniphier(-f): remove all dev_dbg()\n  i2c: uniphier(-f): use devm_platform_ioremap_resource()\n  i2c: slave-eeprom: Add comment about address handling\n  i2c: exynos5: Remove IRQF_ONESHOT\n  i2c: stm32f7: Make structure stm32f7_i2c_algo constant\n  i2c: cht-wc: drop check because i2c_unregister_device() is NULL safe\n  i2c-eeprom_slave: Add support for more eeprom models\n  i2c: fsi: Add of_put_node() before break\n  i2c: synquacer: Make synquacer_i2c_ops constant\n  i2c: hix5hd2: Remove IRQF_ONESHOT\n  i2c: i801: Use iTCO version 6 in Cannon Lake PCH and beyond\n  watchdog: iTCO: Add support for Cannon Lake PCH iTCO\n  i2c: iproc: Make bcm_iproc_i2c_quirks constant\n  i2c: iproc: Add full name of devicetree node to adapter name\n  i2c: piix4: Add ACPI support\n  i2c: piix4: Fix probing of reserved ports on AMD Family 16h Model 30h\n  i2c: ocores: use request_any_context_irq() to register IRQ handler\n  i2c: designware: Fix optional reset error handling\n  ...",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEwMjQwMjU=",
                      "login": "torvalds"
                    },
                    "name": "Linus Torvalds",
                    "email": "torvalds@linux-foundation.org",
                    "date": "2019-09-24T16:48:02.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "Merge tag 'sound-fix-5.4-rc1' of git://git.kernel.org/pub/scm/linux/k…",
                  "message": "Merge tag 'sound-fix-5.4-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/tiwai/sound\n\nPull sound fixes from Takashi Iwai:\n \"A few small remaining wrap-up for this merge window.\n\n  Most of patches are device-specific (HD-audio and USB-audio quirks,\n  FireWire, pcm316a, fsl, rsnd, Atmel, and TI fixes), while there is a\n  simple fix (actually two commits) for ASoC core\"\n\n* tag 'sound-fix-5.4-rc1' of git://git.kernel.org/pub/scm/linux/kernel/git/tiwai/sound:\n  ALSA: usb-audio: Add DSD support for EVGA NU Audio\n  ALSA: hda - Add laptop imic fixup for ASUS M9V laptop\n  ASoC: ti: fix SND_SOC_DM365_VOICE_CODEC dependencies\n  ASoC: pcm3168a: The codec does not support S32_LE\n  ASoC: core: use list_del_init and move it back to soc_cleanup_component\n  ALSA: hda/realtek - PCI quirk for Medion E4254\n  ALSA: hda - Apply AMD controller workaround for Raven platform\n  ASoC: rsnd: do error check after rsnd_channel_normalization()\n  ASoC: atmel_ssc_dai: Remove wrong spinlock usage\n  ASoC: core: delete component->card_list in soc_remove_component only\n  ASoC: fsl_sai: Fix noise when using EDMA\n  ALSA: usb-audio: Add Hiby device family to quirks for native DSD support\n  ALSA: hda/realtek - Fix alienware headset mic\n  ALSA: dice: fix wrong packet parameter for Alesis iO26",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEwMjQwMjU=",
                      "login": "torvalds"
                    },
                    "name": "Linus Torvalds",
                    "email": "torvalds@linux-foundation.org",
                    "date": "2019-09-24T16:46:16.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "Merge tag 'for-5.4/io_uring-2019-09-24' of git://git.kernel.dk/linux-…",
                  "message": "Merge tag 'for-5.4/io_uring-2019-09-24' of git://git.kernel.dk/linux-block\n\nPull more io_uring updates from Jens Axboe:\n \"A collection of later fixes and additions, that weren't quite ready\n  for pushing out with the initial pull request.\n\n  This contains:\n\n   - Fix potential use-after-free of shadow requests (Jackie)\n\n   - Fix potential OOM crash in request allocation (Jackie)\n\n   - kmalloc+memcpy -> kmemdup cleanup (Jackie)\n\n   - Fix poll crash regression (me)\n\n   - Fix SQ thread not being nice and giving up CPU for !PREEMPT (me)\n\n   - Add support for timeouts, making it easier to do epoll_wait()\n     conversions, for instance (me)\n\n   - Ensure io_uring works without f_ops->read_iter() and\n     f_ops->write_iter() (me)\"\n\n* tag 'for-5.4/io_uring-2019-09-24' of git://git.kernel.dk/linux-block:\n  io_uring: correctly handle non ->{read,write}_iter() file_operations\n  io_uring: IORING_OP_TIMEOUT support\n  io_uring: use cond_resched() in sqthread\n  io_uring: fix potential crash issue due to io_get_req failure\n  io_uring: ensure poll commands clear ->sqe\n  io_uring: fix use-after-free of shadow_req\n  io_uring: use kmemdup instead of kmalloc and memcpy",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEwMjQwMjU=",
                      "login": "torvalds"
                    },
                    "name": "Linus Torvalds",
                    "email": "torvalds@linux-foundation.org",
                    "date": "2019-09-24T16:40:21.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "Merge tag 'for-5.4/post-2019-09-24' of git://git.kernel.dk/linux-block",
                  "message": "Merge tag 'for-5.4/post-2019-09-24' of git://git.kernel.dk/linux-block\n\nPull more block updates from Jens Axboe:\n \"Some later additions that weren't quite done for the first pull\n  request, and also a few fixes that have arrived since.\n\n  This contains:\n\n   - Kill silly pktcdvd warning on attempting to register a non-scsi\n     passthrough device (me)\n\n   - Use symbolic constants for the block t10 protection types, and\n     switch to handling it in core rather than in the drivers (Max)\n\n   - libahci platform missing node put fix (Nishka)\n\n   - Small series of fixes for BFQ (Paolo)\n\n   - Fix possible nbd crash (Xiubo)\"\n\n* tag 'for-5.4/post-2019-09-24' of git://git.kernel.dk/linux-block:\n  block: drop device references in bsg_queue_rq()\n  block: t10-pi: fix -Wswitch warning\n  pktcdvd: remove warning on attempting to register non-passthrough dev\n  ata: libahci_platform: Add of_node_put() before loop exit\n  nbd: fix possible page fault for nbd disk\n  nbd: rename the runtime flags as NBD_RT_ prefixed\n  block, bfq: push up injection only after setting service time\n  block, bfq: increase update frequency of inject limit\n  block, bfq: reduce upper bound for inject limit to max_rq_in_driver+1\n  block, bfq: update inject limit only after injection occurred\n  block: centralize PI remapping logic to the block layer\n  block: use symbolic constants for t10_pi type",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEwMjQwMjU=",
                      "login": "torvalds"
                    },
                    "name": "Linus Torvalds",
                    "email": "torvalds@linux-foundation.org",
                    "date": "2019-09-24T16:31:50.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "Merge branch 'akpm' (patches from Andrew)",
                  "message": "Merge branch 'akpm' (patches from Andrew)\n\nMerge updates from Andrew Morton:\n\n - a few hot fixes\n\n - ocfs2 updates\n\n - almost all of -mm (slab-generic, slab, slub, kmemleak, kasan,\n   cleanups, debug, pagecache, memcg, gup, pagemap, memory-hotplug,\n   sparsemem, vmalloc, initialization, z3fold, compaction, mempolicy,\n   oom-kill, hugetlb, migration, thp, mmap, madvise, shmem, zswap,\n   zsmalloc)\n\n* emailed patches from Andrew Morton <akpm@linux-foundation.org>: (132 commits)\n  mm/zsmalloc.c: fix a -Wunused-function warning\n  zswap: do not map same object twice\n  zswap: use movable memory if zpool support allocate movable memory\n  zpool: add malloc_support_movable to zpool_driver\n  shmem: fix obsolete comment in shmem_getpage_gfp()\n  mm/madvise: reduce code duplication in error handling paths\n  mm: mmap: increase sockets maximum memory size pgoff for 32bits\n  mm/mmap.c: refine find_vma_prev() with rb_last()\n  riscv: make mmap allocation top-down by default\n  mips: use generic mmap top-down layout and brk randomization\n  mips: replace arch specific way to determine 32bit task with generic version\n  mips: adjust brk randomization offset to fit generic version\n  mips: use STACK_TOP when computing mmap base address\n  mips: properly account for stack randomization and stack guard gap\n  arm: use generic mmap top-down layout and brk randomization\n  arm: use STACK_TOP when computing mmap base address\n  arm: properly account for stack randomization and stack guard gap\n  arm64, mm: make randomization selected by generic topdown mmap layout\n  arm64, mm: move generic mmap layout functions to mm\n  arm64: consider stack randomization for mmap base only when necessary\n  ...",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEwMjQwMjU=",
                      "login": "torvalds"
                    },
                    "name": "Linus Torvalds",
                    "email": "torvalds@linux-foundation.org",
                    "date": "2019-09-24T16:10:23.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/zsmalloc.c: fix a -Wunused-function warning",
                  "message": "mm/zsmalloc.c: fix a -Wunused-function warning\n\nset_zspage_inuse() was introduced in the commit 4f42047bbde0 (\"zsmalloc:\nuse accessor\") but all the users of it were removed later by the commits,\n\nbdb0af7ca8f0 (\"zsmalloc: factor page chain functionality out\")\n3783689a1aa8 (\"zsmalloc: introduce zspage structure\")\n\nso the function can be safely removed now.\n\nLink: http://lkml.kernel.org/r/1568658408-19374-1-git-send-email-cai@lca.pw\nSigned-off-by: Qian Cai <cai@lca.pw>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjUwNzA4MTYx",
                      "login": "cailca"
                    },
                    "name": "Qian Cai",
                    "email": "cai@lca.pw",
                    "date": "2019-09-23T15:39:46.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "zswap: do not map same object twice",
                  "message": "zswap: do not map same object twice\n\nzswap_writeback_entry() maps a handle to read swpentry first, and\nthen in the most common case it would map the same handle again.\nThis is ok when zbud is the backend since its mapping callback is\nplain and simple, but it slows things down for z3fold.\n\nSince there's hardly a point in unmapping a handle _that_ fast as\nzswap_writeback_entry() does when it reads swpentry, the\nsuggestion is to keep the handle mapped till the end.\n\nLink: http://lkml.kernel.org/r/20190916004640.b453167d3556c4093af4cf7d@gmail.com\nSigned-off-by: Vitaly Wool <vitalywool@gmail.com>\nReviewed-by: Dan Streetman <ddstreet@ieee.org>\nCc: Shakeel Butt <shakeelb@google.com>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>\nCc: Seth Jennings <sjenning@redhat.com>\nCc: Vitaly Wool <vitalywool@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE2MDg2NTgw",
                      "login": "vwool"
                    },
                    "name": "Vitaly Wool",
                    "email": "vitalywool@gmail.com",
                    "date": "2019-09-23T15:39:43.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "zswap: use movable memory if zpool support allocate movable memory",
                  "message": "zswap: use movable memory if zpool support allocate movable memory\n\nThis is the third version that was updated according to the comments from\nSergey Senozhatsky https://lkml.org/lkml/2019/5/29/73 and Shakeel Butt\nhttps://lkml.org/lkml/2019/6/4/973\n\nzswap compresses swap pages into a dynamically allocated RAM-based memory\npool.  The memory pool should be zbud, z3fold or zsmalloc.  All of them\nwill allocate unmovable pages.  It will increase the number of unmovable\npage blocks that will bad for anti-fragment.\n\nzsmalloc support page migration if request movable page:\n        handle = zs_malloc(zram->mem_pool, comp_len,\n                GFP_NOIO | __GFP_HIGHMEM |\n                __GFP_MOVABLE);\n\nAnd commit \"zpool: Add malloc_support_movable to zpool_driver\" add\nzpool_malloc_support_movable check malloc_support_movable to make sure if\na zpool support allocate movable memory.\n\nThis commit let zswap allocate block with gfp\n__GFP_HIGHMEM | __GFP_MOVABLE if zpool support allocate movable memory.\n\nFollowing part is test log in a pc that has 8G memory and 2G swap.\n\nWithout this commit:\n~# echo lz4 > /sys/module/zswap/parameters/compressor\n~# echo zsmalloc > /sys/module/zswap/parameters/zpool\n~# echo 1 > /sys/module/zswap/parameters/enabled\n~# swapon /swapfile\n~# cd /home/teawater/kernel/vm-scalability/\n/home/teawater/kernel/vm-scalability# export unit_size=$((9 * 1024 * 1024 * 1024))\n/home/teawater/kernel/vm-scalability# ./case-anon-w-seq\n2717908992 bytes / 4826062 usecs = 549973 KB/s\n2717908992 bytes / 4864201 usecs = 545661 KB/s\n2717908992 bytes / 4867015 usecs = 545346 KB/s\n2717908992 bytes / 4915485 usecs = 539968 KB/s\n397853 usecs to free memory\n357820 usecs to free memory\n421333 usecs to free memory\n420454 usecs to free memory\n/home/teawater/kernel/vm-scalability# cat /proc/pagetypeinfo\nPage block order: 9\nPages per block:  512\n\nFree pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10\nNode    0, zone      DMA, type    Unmovable      1      1      1      0      2      1      1      0      1      0      0\nNode    0, zone      DMA, type      Movable      0      0      0      0      0      0      0      0      0      1      3\nNode    0, zone      DMA, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone      DMA, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone      DMA, type          CMA      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone      DMA, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone    DMA32, type    Unmovable      6      5      8      6      6      5      4      1      1      1      0\nNode    0, zone    DMA32, type      Movable     25     20     20     19     22     15     14     11     11      5    767\nNode    0, zone    DMA32, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone    DMA32, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone    DMA32, type          CMA      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone    DMA32, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type    Unmovable   4753   5588   5159   4613   3712   2520   1448    594    188     11      0\nNode    0, zone   Normal, type      Movable     16      3    457   2648   2143   1435    860    459    223    224    296\nNode    0, zone   Normal, type  Reclaimable      0      0     44     38     11      2      0      0      0      0      0\nNode    0, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type          CMA      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\n\nNumber of blocks type     Unmovable      Movable  Reclaimable   HighAtomic          CMA      Isolate\nNode 0, zone      DMA            1            7            0            0            0            0\nNode 0, zone    DMA32            4         1652            0            0            0            0\nNode 0, zone   Normal          931         1485           15            0            0            0\n\nWith this commit:\n~# echo lz4 > /sys/module/zswap/parameters/compressor\n~# echo zsmalloc > /sys/module/zswap/parameters/zpool\n~# echo 1 > /sys/module/zswap/parameters/enabled\n~# swapon /swapfile\n~# cd /home/teawater/kernel/vm-scalability/\n/home/teawater/kernel/vm-scalability# export unit_size=$((9 * 1024 * 1024 * 1024))\n/home/teawater/kernel/vm-scalability# ./case-anon-w-seq\n2717908992 bytes / 4689240 usecs = 566020 KB/s\n2717908992 bytes / 4760605 usecs = 557535 KB/s\n2717908992 bytes / 4803621 usecs = 552543 KB/s\n2717908992 bytes / 5069828 usecs = 523530 KB/s\n431546 usecs to free memory\n383397 usecs to free memory\n456454 usecs to free memory\n224487 usecs to free memory\n/home/teawater/kernel/vm-scalability# cat /proc/pagetypeinfo\nPage block order: 9\nPages per block:  512\n\nFree pages count per migrate type at order       0      1      2      3      4      5      6      7      8      9     10\nNode    0, zone      DMA, type    Unmovable      1      1      1      0      2      1      1      0      1      0      0\nNode    0, zone      DMA, type      Movable      0      0      0      0      0      0      0      0      0      1      3\nNode    0, zone      DMA, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone      DMA, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone      DMA, type          CMA      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone      DMA, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone    DMA32, type    Unmovable     10      8     10      9     10      4      3      2      3      0      0\nNode    0, zone    DMA32, type      Movable     18     12     14     16     16     11      9      5      5      6    775\nNode    0, zone    DMA32, type  Reclaimable      0      0      0      0      0      0      0      0      0      0      1\nNode    0, zone    DMA32, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone    DMA32, type          CMA      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone    DMA32, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type    Unmovable   2669   1236    452    118     37     14      4      1      2      3      0\nNode    0, zone   Normal, type      Movable   3850   6086   5274   4327   3510   2494   1520    934    438    220    470\nNode    0, zone   Normal, type  Reclaimable     56     93    155    124     47     31     17      7      3      0      0\nNode    0, zone   Normal, type   HighAtomic      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type          CMA      0      0      0      0      0      0      0      0      0      0      0\nNode    0, zone   Normal, type      Isolate      0      0      0      0      0      0      0      0      0      0      0\n\nNumber of blocks type     Unmovable      Movable  Reclaimable   HighAtomic          CMA      Isolate\nNode 0, zone      DMA            1            7            0            0            0            0\nNode 0, zone    DMA32            4         1650            2            0            0            0\nNode 0, zone   Normal           79         2326           26            0            0            0\n\nYou can see that the number of unmovable page blocks is decreased\nwhen the kernel has this commit.\n\nLink: http://lkml.kernel.org/r/20190605100630.13293-2-teawaterz@linux.alibaba.com\nSigned-off-by: Hui Zhu <teawaterz@linux.alibaba.com>\nReviewed-by: Shakeel Butt <shakeelb@google.com>\nCc: Dan Streetman <ddstreet@ieee.org>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Nitin Gupta <ngupta@vflare.org>\nCc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>\nCc: Seth Jennings <sjenning@redhat.com>\nCc: Vitaly Wool <vitalywool@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjQzMjM4Mg==",
                      "login": "teawater"
                    },
                    "name": "Hui Zhu",
                    "email": "teawaterz@linux.alibaba.com",
                    "date": "2019-09-23T15:39:40.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "zpool: add malloc_support_movable to zpool_driver",
                  "message": "zpool: add malloc_support_movable to zpool_driver\n\nAs a zpool_driver, zsmalloc can allocate movable memory because it support\nmigate pages.  But zbud and z3fold cannot allocate movable memory.\n\nAdd malloc_support_movable to zpool_driver.  If a zpool_driver support\nallocate movable memory, set it to true.  And add\nzpool_malloc_support_movable check malloc_support_movable to make sure if\na zpool support allocate movable memory.\n\nLink: http://lkml.kernel.org/r/20190605100630.13293-1-teawaterz@linux.alibaba.com\nSigned-off-by: Hui Zhu <teawaterz@linux.alibaba.com>\nReviewed-by: Shakeel Butt <shakeelb@google.com>\nCc: Dan Streetman <ddstreet@ieee.org>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Nitin Gupta <ngupta@vflare.org>\nCc: Sergey Senozhatsky <sergey.senozhatsky.work@gmail.com>\nCc: Seth Jennings <sjenning@redhat.com>\nCc: Vitaly Wool <vitalywool@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjQzMjM4Mg==",
                      "login": "teawater"
                    },
                    "name": "Hui Zhu",
                    "email": "teawaterz@linux.alibaba.com",
                    "date": "2019-09-23T15:39:37.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "shmem: fix obsolete comment in shmem_getpage_gfp()",
                  "message": "shmem: fix obsolete comment in shmem_getpage_gfp()\n\nReplace \"fault_mm\" with \"vmf\" in code comment because commit cfda05267f7b\n(\"userfaultfd: shmem: add userfaultfd hook for shared memory faults\") has\nchanged the prototpye of shmem_getpage_gfp() - pass vmf instead of\nfault_mm to the function.\n\nBefore:\nstatic int shmem_getpage_gfp(struct inode *inode, pgoff_t index,\n\t\tstruct page **pagep, enum sgp_type sgp,\n\t\tgfp_t gfp, struct mm_struct *fault_mm, int *fault_type);\nAfter:\nstatic int shmem_getpage_gfp(struct inode *inode, pgoff_t index,\n\t\tstruct page **pagep, enum sgp_type sgp,\n\t\tgfp_t gfp, struct vm_area_struct *vma,\n\t\tstruct vm_fault *vmf, vm_fault_t *fault_type);\n\nLink: http://lkml.kernel.org/r/20190816100204.9781-1-miles.chen@mediatek.com\nSigned-off-by: Miles Chen <miles.chen@mediatek.com>\nCc: Hugh Dickins <hughd@google.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Miles Chen",
                    "email": "miles.chen@mediatek.com",
                    "date": "2019-09-23T15:39:34.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/madvise: reduce code duplication in error handling paths",
                  "message": "mm/madvise: reduce code duplication in error handling paths\n\nmadvise_behavior() converts -ENOMEM to -EAGAIN in several places using\nidentical code.\n\nMove that code to a common error handling path.\n\nNo functional changes.\n\nLink: http://lkml.kernel.org/r/1564640896-1210-1-git-send-email-rppt@linux.ibm.com\nSigned-off-by: Mike Rapoport <rppt@linux.ibm.com>\nAcked-by: Pankaj Gupta <pagupta@redhat.com>\nReviewed-by: Anshuman Khandual <anshuman.khandual@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Mike Rapoport",
                    "email": "rppt@linux.ibm.com",
                    "date": "2019-09-23T15:39:31.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: mmap: increase sockets maximum memory size pgoff for 32bits",
                  "message": "mm: mmap: increase sockets maximum memory size pgoff for 32bits\n\nThe AF_XDP sockets umem mapping interface uses XDP_UMEM_PGOFF_FILL_RING\nand XDP_UMEM_PGOFF_COMPLETION_RING offsets.  These offsets are\nestablished already and are part of the configuration interface.\n\nBut for 32-bit systems, using AF_XDP socket configuration, these values\nare too large to pass the maximum allowed file size verification.  The\noffsets can be tuned off, but instead of changing the existing\ninterface, let's extend the max allowed file size for sockets.\n\nNo one has been using this until this patch with 32 bits as without\nthis fix af_xdp sockets can't be used at all, so it unblocks af_xdp\nsocket usage for 32bit systems.\n\nAll list of mmap cbs for sockets was verified for side effects and all\nof them contain dummy cb - sock_no_mmap() at this moment, except the\nfollowing:\n\nxsk_mmap() - it's what this fix is needed for.\ntcp_mmap() - doesn't have obvious issues with pgoff - no any references on it.\npacket_mmap() - return -EINVAL if it's even set.\n\nLink: http://lkml.kernel.org/r/20190812124326.32146-1-ivan.khoronzhuk@linaro.org\nSigned-off-by: Ivan Khoronzhuk <ivan.khoronzhuk@linaro.org>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Björn Töpel <bjorn.topel@intel.com>\nCc: Alexei Starovoitov <ast@kernel.org>\nCc: Magnus Karlsson <magnus.karlsson@intel.com>\nCc: Daniel Borkmann <daniel@iogearbox.net>\nCc: David Miller <davem@davemloft.net>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjQ0OTgwNjg=",
                      "login": "ikhorn"
                    },
                    "name": "Ivan Khoronzhuk",
                    "email": "ivan.khoronzhuk@linaro.org",
                    "date": "2019-09-23T15:39:28.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/mmap.c: refine find_vma_prev() with rb_last()",
                  "message": "mm/mmap.c: refine find_vma_prev() with rb_last()\n\nWhen addr is out of range of the whole rb_tree, pprev will point to the\nright-most node.  rb_tree facility already provides a helper function,\nrb_last(), to do this task.  We can leverage this instead of\nreimplementing it.\n\nThis patch refines find_vma_prev() with rb_last() to make it a little\nnicer to read.\n\n[akpm@linux-foundation.org: little cleanup, per Vlastimil]\nLink: http://lkml.kernel.org/r/20190809001928.4950-1-richardw.yang@linux.intel.com\nSigned-off-by: Wei Yang <richardw.yang@linux.intel.com>\nAcked-by: Vlastimil Babka <vbabka@suse.cz>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Wei Yang",
                    "email": "richardw.yang@linux.intel.com",
                    "date": "2019-09-23T15:39:25.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "riscv: make mmap allocation top-down by default",
                  "message": "riscv: make mmap allocation top-down by default\n\nIn order to avoid wasting user address space by using bottom-up mmap\nallocation scheme, prefer top-down scheme when possible.\n\nBefore:\nroot@qemuriscv64:~# cat /proc/self/maps\n00010000-00016000 r-xp 00000000 fe:00 6389       /bin/cat.coreutils\n00016000-00017000 r--p 00005000 fe:00 6389       /bin/cat.coreutils\n00017000-00018000 rw-p 00006000 fe:00 6389       /bin/cat.coreutils\n00018000-00039000 rw-p 00000000 00:00 0          [heap]\n1555556000-155556d000 r-xp 00000000 fe:00 7193   /lib/ld-2.28.so\n155556d000-155556e000 r--p 00016000 fe:00 7193   /lib/ld-2.28.so\n155556e000-155556f000 rw-p 00017000 fe:00 7193   /lib/ld-2.28.so\n155556f000-1555570000 rw-p 00000000 00:00 0\n1555570000-1555572000 r-xp 00000000 00:00 0      [vdso]\n1555574000-1555576000 rw-p 00000000 00:00 0\n1555576000-1555674000 r-xp 00000000 fe:00 7187   /lib/libc-2.28.so\n1555674000-1555678000 r--p 000fd000 fe:00 7187   /lib/libc-2.28.so\n1555678000-155567a000 rw-p 00101000 fe:00 7187   /lib/libc-2.28.so\n155567a000-15556a0000 rw-p 00000000 00:00 0\n3fffb90000-3fffbb1000 rw-p 00000000 00:00 0      [stack]\n\nAfter:\nroot@qemuriscv64:~# cat /proc/self/maps\n00010000-00016000 r-xp 00000000 fe:00 6389       /bin/cat.coreutils\n00016000-00017000 r--p 00005000 fe:00 6389       /bin/cat.coreutils\n00017000-00018000 rw-p 00006000 fe:00 6389       /bin/cat.coreutils\n2de81000-2dea2000 rw-p 00000000 00:00 0          [heap]\n3ff7eb6000-3ff7ed8000 rw-p 00000000 00:00 0\n3ff7ed8000-3ff7fd6000 r-xp 00000000 fe:00 7187   /lib/libc-2.28.so\n3ff7fd6000-3ff7fda000 r--p 000fd000 fe:00 7187   /lib/libc-2.28.so\n3ff7fda000-3ff7fdc000 rw-p 00101000 fe:00 7187   /lib/libc-2.28.so\n3ff7fdc000-3ff7fe2000 rw-p 00000000 00:00 0\n3ff7fe4000-3ff7fe6000 r-xp 00000000 00:00 0      [vdso]\n3ff7fe6000-3ff7ffd000 r-xp 00000000 fe:00 7193   /lib/ld-2.28.so\n3ff7ffd000-3ff7ffe000 r--p 00016000 fe:00 7193   /lib/ld-2.28.so\n3ff7ffe000-3ff7fff000 rw-p 00017000 fe:00 7193   /lib/ld-2.28.so\n3ff7fff000-3ff8000000 rw-p 00000000 00:00 0\n3fff888000-3fff8a9000 rw-p 00000000 00:00 0      [stack]\n\n[alex@ghiti.fr: v6]\n  Link: http://lkml.kernel.org/r/20190808061756.19712-15-alex@ghiti.fr\nLink: http://lkml.kernel.org/r/20190730055113.23635-15-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nAcked-by: Paul Walmsley <paul.walmsley@sifive.com>\t[arch/riscv]\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:39:21.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mips: use generic mmap top-down layout and brk randomization",
                  "message": "mips: use generic mmap top-down layout and brk randomization\n\nmips uses a top-down layout by default that exactly fits the generic\nfunctions, so get rid of arch specific code and use the generic version by\nselecting ARCH_WANT_DEFAULT_TOPDOWN_MMAP_LAYOUT.\n\nAs ARCH_WANT_DEFAULT_TOPDOWN_MMAP_LAYOUT selects ARCH_HAS_ELF_RANDOMIZE,\nuse the generic version of arch_randomize_brk since it also fits.  Note\nthat this commit also removes the possibility for mips to have elf\nrandomization and no MMU: without MMU, the security added by randomization\nis worth nothing.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-14-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Paul Burton <paul.burton@mips.com>\nReviewed-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:39:18.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mips: replace arch specific way to determine 32bit task with generic …",
                  "message": "mips: replace arch specific way to determine 32bit task with generic version\n\nMips uses TASK_IS_32BIT_ADDR to determine if a task is 32bit, but this\ndefine is mips specific and other arches do not have it: instead, use\n!IS_ENABLED(CONFIG_64BIT) || is_compat_task() condition.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-13-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Paul Burton <paul.burton@mips.com>\nReviewed-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:39:14.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mips: adjust brk randomization offset to fit generic version",
                  "message": "mips: adjust brk randomization offset to fit generic version\n\nThis commit simply bumps up to 32MB and 1GB the random offset of brk,\ncompared to 8MB and 256MB, for 32bit and 64bit respectively.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-12-alex@ghiti.fr\nSuggested-by: Kees Cook <keescook@chromium.org>\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Paul Burton <paul.burton@mips.com>\nReviewed-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:39:11.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mips: use STACK_TOP when computing mmap base address",
                  "message": "mips: use STACK_TOP when computing mmap base address\n\nmmap base address must be computed wrt stack top address, using TASK_SIZE\nis wrong since STACK_TOP and TASK_SIZE are not equivalent.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-11-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Kees Cook <keescook@chromium.org>\nAcked-by: Paul Burton <paul.burton@mips.com>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:39:07.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mips: properly account for stack randomization and stack guard gap",
                  "message": "mips: properly account for stack randomization and stack guard gap\n\nThis commit takes care of stack randomization and stack guard gap when\ncomputing mmap base address and checks if the task asked for\nrandomization.  This fixes the problem uncovered and not fixed for arm\nhere: https://lkml.kernel.org/r/20170622200033.25714-1-riel@redhat.com\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-10-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Kees Cook <keescook@chromium.org>\nAcked-by: Paul Burton <paul.burton@mips.com>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:39:04.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "arm: use generic mmap top-down layout and brk randomization",
                  "message": "arm: use generic mmap top-down layout and brk randomization\n\narm uses a top-down mmap layout by default that exactly fits the generic\nfunctions, so get rid of arch specific code and use the generic version by\nselecting ARCH_WANT_DEFAULT_TOPDOWN_MMAP_LAYOUT.\n\nAs ARCH_WANT_DEFAULT_TOPDOWN_MMAP_LAYOUT selects ARCH_HAS_ELF_RANDOMIZE,\nuse the generic version of arch_randomize_brk since it also fits.  Note\nthat this commit also removes the possibility for arm to have elf\nrandomization and no MMU: without MMU, the security added by randomization\nis worth nothing.\n\nNote that it is safe to remove STACK_RND_MASK since it matches the default\nvalue.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-9-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:39:01.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "arm: use STACK_TOP when computing mmap base address",
                  "message": "arm: use STACK_TOP when computing mmap base address\n\nmmap base address must be computed wrt stack top address, using TASK_SIZE\nis wrong since STACK_TOP and TASK_SIZE are not equivalent.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-8-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:38:57.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "arm: properly account for stack randomization and stack guard gap",
                  "message": "arm: properly account for stack randomization and stack guard gap\n\nThis commit takes care of stack randomization and stack guard gap when\ncomputing mmap base address and checks if the task asked for\nrandomization.  This fixes the problem uncovered and not fixed for arm\nhere: https://lkml.kernel.org/r/20170622200033.25714-1-riel@redhat.com\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-7-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: Christoph Hellwig <hch@lst.de>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:38:54.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "arm64, mm: make randomization selected by generic topdown mmap layout",
                  "message": "arm64, mm: make randomization selected by generic topdown mmap layout\n\nThis commits selects ARCH_HAS_ELF_RANDOMIZE when an arch uses the generic\ntopdown mmap layout functions so that this security feature is on by\ndefault.\n\nNote that this commit also removes the possibility for arm64 to have elf\nrandomization and no MMU: without MMU, the security added by randomization\nis worth nothing.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-6-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Catalin Marinas <catalin.marinas@arm.com>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:38:50.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "arm64, mm: move generic mmap layout functions to mm",
                  "message": "arm64, mm: move generic mmap layout functions to mm\n\narm64 handles top-down mmap layout in a way that can be easily reused by\nother architectures, so make it available in mm.  It then introduces a new\nconfig ARCH_WANT_DEFAULT_TOPDOWN_MMAP_LAYOUT that can be set by other\narchitectures to benefit from those functions.  Note that this new config\ndepends on MMU being enabled, if selected without MMU support, a warning\nwill be thrown.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-5-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nSuggested-by: Christoph Hellwig <hch@infradead.org>\nAcked-by: Catalin Marinas <catalin.marinas@arm.com>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:38:47.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "arm64: consider stack randomization for mmap base only when necessary",
                  "message": "arm64: consider stack randomization for mmap base only when necessary\n\nDo not offset mmap base address because of stack randomization if current\ntask does not want randomization.  Note that x86 already implements this\nbehaviour.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-4-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Catalin Marinas <catalin.marinas@arm.com>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:38:43.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "arm64: make use of is_compat_task instead of hardcoding this test",
                  "message": "arm64: make use of is_compat_task instead of hardcoding this test\n\nEach architecture has its own way to determine if a task is a compat task,\nby using is_compat_task in arch_mmap_rnd, it allows more genericity and\nthen it prepares its moving to mm/.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-3-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Catalin Marinas <catalin.marinas@arm.com>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Christoph Hellwig <hch@infradead.org>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Paul Burton <paul.burton@mips.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Will Deacon <will.deacon@arm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:38:40.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm, fs: move randomize_stack_top from fs to mm",
                  "message": "mm, fs: move randomize_stack_top from fs to mm\n\nPatch series \"Provide generic top-down mmap layout functions\", v6.\n\nThis series introduces generic functions to make top-down mmap layout\neasily accessible to architectures, in particular riscv which was the\ninitial goal of this series.  The generic implementation was taken from\narm64 and used successively by arm, mips and finally riscv.\n\nNote that in addition the series fixes 2 issues:\n\n- stack randomization was taken into account even if not necessary.\n\n- [1] fixed an issue with mmap base which did not take into account\n  randomization but did not report it to arm and mips, so by moving arm64\n  into a generic library, this problem is now fixed for both\n  architectures.\n\nThis work is an effort to factorize architecture functions to avoid code\nduplication and oversights as in [1].\n\n[1]: https://www.mail-archive.com/linux-kernel@vger.kernel.org/msg1429066.html\n\nThis patch (of 14):\n\nThis preparatory commit moves this function so that further introduction\nof generic topdown mmap layout is contained only in mm/util.c.\n\nLink: http://lkml.kernel.org/r/20190730055113.23635-2-alex@ghiti.fr\nSigned-off-by: Alexandre Ghiti <alex@ghiti.fr>\nAcked-by: Kees Cook <keescook@chromium.org>\nReviewed-by: Christoph Hellwig <hch@lst.de>\nReviewed-by: Luis Chamberlain <mcgrof@kernel.org>\nCc: Russell King <linux@armlinux.org.uk>\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Will Deacon <will.deacon@arm.com>\nCc: Ralf Baechle <ralf@linux-mips.org>\nCc: Paul Burton <paul.burton@mips.com>\nCc: James Hogan <jhogan@kernel.org>\nCc: Palmer Dabbelt <palmer@sifive.com>\nCc: Albert Ou <aou@eecs.berkeley.edu>\nCc: Alexander Viro <viro@zeniv.linux.org.uk>\nCc: Christoph Hellwig <hch@infradead.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk0NDM4MDU=",
                      "login": "AlexGhiti"
                    },
                    "name": "Alexandre Ghiti",
                    "email": "alex@ghiti.fr",
                    "date": "2019-09-23T15:38:37.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "uprobe: collapse THP pmd after removing all uprobes",
                  "message": "uprobe: collapse THP pmd after removing all uprobes\n\nAfter all uprobes are removed from the huge page (with PTE pgtable), it is\npossible to collapse the pmd and benefit from THP again.  This patch does\nthe collapse by calling collapse_pte_mapped_thp().\n\nLink: http://lkml.kernel.org/r/20190815164525.1848545-7-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReported-by: kbuild test robot <lkp@intel.com>\nReviewed-by: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:33.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "khugepaged: enable collapse pmd for pte-mapped THP",
                  "message": "khugepaged: enable collapse pmd for pte-mapped THP\n\nkhugepaged needs exclusive mmap_sem to access page table.  When it fails\nto lock mmap_sem, the page will fault in as pte-mapped THP.  As the page\nis already a THP, khugepaged will not handle this pmd again.\n\nThis patch enables the khugepaged to retry collapse the page table.\n\nstruct mm_slot (in khugepaged.c) is extended with an array, containing\naddresses of pte-mapped THPs.  We use array here for simplicity.  We can\neasily replace it with more advanced data structures when needed.\n\nIn khugepaged_scan_mm_slot(), if the mm contains pte-mapped THP, we try to\ncollapse the page table.\n\nSince collapse may happen at an later time, some pages may already fault\nin.  collapse_pte_mapped_thp() is added to properly handle these pages.\ncollapse_pte_mapped_thp() also double checks whether all ptes in this pmd\nare mapping to the same THP.  This is necessary because some subpage of\nthe THP may be replaced, for example by uprobe.  In such cases, it is not\npossible to collapse the pmd.\n\n[kirill.shutemov@linux.intel.com: add comments for retract_page_tables()]\n  Link: http://lkml.kernel.org/r/20190816145443.6ard3iilytc6jlgv@box\nLink: http://lkml.kernel.org/r/20190815164525.1848545-6-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nSigned-off-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nSuggested-by: Johannes Weiner <hannes@cmpxchg.org>\nReviewed-by: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:30.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "uprobe: use FOLL_SPLIT_PMD instead of FOLL_SPLIT",
                  "message": "uprobe: use FOLL_SPLIT_PMD instead of FOLL_SPLIT\n\nUse the newly added FOLL_SPLIT_PMD in uprobe.  This preserves the huge\npage when the uprobe is enabled.  When the uprobe is disabled, newer\ninstances of the same application could still benefit from huge page.\n\nFor the next step, we will enable khugepaged to regroup the pmd, so that\nexisting instances of the application could also benefit from huge page\nafter the uprobe is disabled.\n\nLink: http://lkml.kernel.org/r/20190815164525.1848545-5-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReviewed-by: Srikar Dronamraju <srikar@linux.vnet.ibm.com>\nReviewed-by: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:27.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm, thp: introduce FOLL_SPLIT_PMD",
                  "message": "mm, thp: introduce FOLL_SPLIT_PMD\n\nIntroduce a new foll_flag: FOLL_SPLIT_PMD.  As the name says\nFOLL_SPLIT_PMD splits huge pmd for given mm_struct, the underlining huge\npage stays as-is.\n\nFOLL_SPLIT_PMD is useful for cases where we need to use regular pages, but\nwould switch back to huge page and huge pmd on.  One of such example is\nuprobe.  The following patches use FOLL_SPLIT_PMD in uprobe.\n\nLink: http://lkml.kernel.org/r/20190815164525.1848545-4-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nReviewed-by: Oleg Nesterov <oleg@redhat.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:25.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "uprobe: use original page when all uprobes are removed",
                  "message": "uprobe: use original page when all uprobes are removed\n\nCurrently, uprobe swaps the target page with a anonymous page in both\ninstall_breakpoint() and remove_breakpoint().  When all uprobes on a page\nare removed, the given mm is still using an anonymous page (not the\noriginal page).\n\nThis patch allows uprobe to use original page when possible (all uprobes\non the page are already removed, and the original page is in page cache\nand uptodate).\n\nAs suggested by Oleg, we unmap the old_page and let the original page\nfault in.\n\nLink: http://lkml.kernel.org/r/20190815164525.1848545-3-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nSuggested-by: Oleg Nesterov <oleg@redhat.com>\nReviewed-by: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:22.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: move memcmp_pages() and pages_identical()",
                  "message": "mm: move memcmp_pages() and pages_identical()\n\nPatch series \"THP aware uprobe\", v13.\n\nThis patchset makes uprobe aware of THPs.\n\nCurrently, when uprobe is attached to text on THP, the page is split by\nFOLL_SPLIT.  As a result, uprobe eliminates the performance benefit of\nTHP.\n\nThis set makes uprobe THP-aware.  Instead of FOLL_SPLIT, we introduces\nFOLL_SPLIT_PMD, which only split PMD for uprobe.\n\nAfter all uprobes within the THP are removed, the PTE-mapped pages are\nregrouped as huge PMD.\n\nThis set (plus a few THP patches) is also available at\n\n   https://github.com/liu-song-6/linux/tree/uprobe-thp\n\nThis patch (of 6):\n\nMove memcmp_pages() to mm/util.c and pages_identical() to mm.h, so that we\ncan use them in other files.\n\nLink: http://lkml.kernel.org/r/20190815164525.1848545-2-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReviewed-by: Oleg Nesterov <oleg@redhat.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Matthew Wilcox <matthew.wilcox@oracle.com>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Srikar Dronamraju <srikar@linux.vnet.ibm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:19.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: thp: make deferred split shrinker memcg aware",
                  "message": "mm: thp: make deferred split shrinker memcg aware\n\nCurrently THP deferred split shrinker is not memcg aware, this may cause\npremature OOM with some configuration.  For example the below test would\nrun into premature OOM easily:\n\n$ cgcreate -g memory:thp\n$ echo 4G > /sys/fs/cgroup/memory/thp/memory/limit_in_bytes\n$ cgexec -g memory:thp transhuge-stress 4000\n\ntranshuge-stress comes from kernel selftest.\n\nIt is easy to hit OOM, but there are still a lot THP on the deferred split\nqueue, memcg direct reclaim can't touch them since the deferred split\nshrinker is not memcg aware.\n\nConvert deferred split shrinker memcg aware by introducing per memcg\ndeferred split queue.  The THP should be on either per node or per memcg\ndeferred split queue if it belongs to a memcg.  When the page is\nimmigrated to the other memcg, it will be immigrated to the target memcg's\ndeferred split queue too.\n\nReuse the second tail page's deferred_list for per memcg list since the\nsame THP can't be on multiple deferred split queues.\n\n[yang.shi@linux.alibaba.com: simplify deferred split queue dereference per Kirill Tkhai]\n  Link: http://lkml.kernel.org/r/1566496227-84952-5-git-send-email-yang.shi@linux.alibaba.com\nLink: http://lkml.kernel.org/r/1565144277-36240-5-git-send-email-yang.shi@linux.alibaba.com\nSigned-off-by: Yang Shi <yang.shi@linux.alibaba.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Michal Hocko <mhocko@suse.com>\nCc: \"Kirill A . Shutemov\" <kirill.shutemov@linux.intel.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: Shakeel Butt <shakeelb@google.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Qian Cai <cai@lca.pw>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjM0NzU2MzE3",
                      "login": "yang-shi"
                    },
                    "name": "Yang Shi",
                    "email": "yang.shi@linux.alibaba.com",
                    "date": "2019-09-23T15:38:15.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: shrinker: make shrinker not depend on memcg kmem",
                  "message": "mm: shrinker: make shrinker not depend on memcg kmem\n\nCurrently shrinker is just allocated and can work when memcg kmem is\nenabled.  But, THP deferred split shrinker is not slab shrinker, it\ndoesn't make too much sense to have such shrinker depend on memcg kmem.\nIt should be able to reclaim THP even though memcg kmem is disabled.\n\nIntroduce a new shrinker flag, SHRINKER_NONSLAB, for non-slab shrinker.\nWhen memcg kmem is disabled, just such shrinkers can be called in\nshrinking memcg slab.\n\n[yang.shi@linux.alibaba.com: add comment]\n  Link: http://lkml.kernel.org/r/1566496227-84952-4-git-send-email-yang.shi@linux.alibaba.com\nLink: http://lkml.kernel.org/r/1565144277-36240-4-git-send-email-yang.shi@linux.alibaba.com\nSigned-off-by: Yang Shi <yang.shi@linux.alibaba.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Michal Hocko <mhocko@suse.com>\nCc: \"Kirill A . Shutemov\" <kirill.shutemov@linux.intel.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: Shakeel Butt <shakeelb@google.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Qian Cai <cai@lca.pw>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjM0NzU2MzE3",
                      "login": "yang-shi"
                    },
                    "name": "Yang Shi",
                    "email": "yang.shi@linux.alibaba.com",
                    "date": "2019-09-23T15:38:12.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: move mem_cgroup_uncharge out of __page_cache_release()",
                  "message": "mm: move mem_cgroup_uncharge out of __page_cache_release()\n\nA later patch makes THP deferred split shrinker memcg aware, but it needs\npage->mem_cgroup information in THP destructor, which is called after\nmem_cgroup_uncharge() now.\n\nSo move mem_cgroup_uncharge() from __page_cache_release() to compound page\ndestructor, which is called by both THP and other compound pages except\nHugeTLB.  And call it in __put_single_page() for single order page.\n\nLink: http://lkml.kernel.org/r/1565144277-36240-3-git-send-email-yang.shi@linux.alibaba.com\nSigned-off-by: Yang Shi <yang.shi@linux.alibaba.com>\nSuggested-by: \"Kirill A . Shutemov\" <kirill.shutemov@linux.intel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: Shakeel Butt <shakeelb@google.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Qian Cai <cai@lca.pw>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjM0NzU2MzE3",
                      "login": "yang-shi"
                    },
                    "name": "Yang Shi",
                    "email": "yang.shi@linux.alibaba.com",
                    "date": "2019-09-23T15:38:09.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: thp: extract split_queue_* into a struct",
                  "message": "mm: thp: extract split_queue_* into a struct\n\nPatch series \"Make deferred split shrinker memcg aware\", v6.\n\nCurrently THP deferred split shrinker is not memcg aware, this may cause\npremature OOM with some configuration.  For example the below test would\nrun into premature OOM easily:\n\n$ cgcreate -g memory:thp\n$ echo 4G > /sys/fs/cgroup/memory/thp/memory/limit_in_bytes\n$ cgexec -g memory:thp transhuge-stress 4000\n\ntranshuge-stress comes from kernel selftest.\n\nIt is easy to hit OOM, but there are still a lot THP on the deferred split\nqueue, memcg direct reclaim can't touch them since the deferred split\nshrinker is not memcg aware.\n\nConvert deferred split shrinker memcg aware by introducing per memcg\ndeferred split queue.  The THP should be on either per node or per memcg\ndeferred split queue if it belongs to a memcg.  When the page is\nimmigrated to the other memcg, it will be immigrated to the target memcg's\ndeferred split queue too.\n\nReuse the second tail page's deferred_list for per memcg list since the\nsame THP can't be on multiple deferred split queues.\n\nMake deferred split shrinker not depend on memcg kmem since it is not\nslab.  It doesn't make sense to not shrink THP even though memcg kmem is\ndisabled.\n\nWith the above change the test demonstrated above doesn't trigger OOM even\nthough with cgroup.memory=nokmem.\n\nThis patch (of 4):\n\nPut split_queue, split_queue_lock and split_queue_len into a struct in\norder to reduce code duplication when we convert deferred_split to memcg\naware in the later patches.\n\nLink: http://lkml.kernel.org/r/1565144277-36240-2-git-send-email-yang.shi@linux.alibaba.com\nSigned-off-by: Yang Shi <yang.shi@linux.alibaba.com>\nSuggested-by: \"Kirill A . Shutemov\" <kirill.shutemov@linux.intel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nReviewed-by: Kirill Tkhai <ktkhai@virtuozzo.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: Shakeel Butt <shakeelb@google.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Qian Cai <cai@lca.pw>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjM0NzU2MzE3",
                      "login": "yang-shi"
                    },
                    "name": "Yang Shi",
                    "email": "yang.shi@linux.alibaba.com",
                    "date": "2019-09-23T15:38:06.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm,thp: avoid writes to file with THP in pagecache",
                  "message": "mm,thp: avoid writes to file with THP in pagecache\n\nIn previous patch, an application could put part of its text section in\nTHP via madvise().  These THPs will be protected from writes when the\napplication is still running (TXTBSY).  However, after the application\nexits, the file is available for writes.\n\nThis patch avoids writes to file THP by dropping page cache for the file\nwhen the file is open for write.  A new counter nr_thps is added to struct\naddress_space.  In do_dentry_open(), if the file is open for write and\nnr_thps is non-zero, we drop page cache for the whole file.\n\nLink: http://lkml.kernel.org/r/20190801184244.3169074-8-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nReported-by: kbuild test robot <lkp@intel.com>\nAcked-by: Rik van Riel <riel@surriel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:03.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm,thp: add read-only THP support for (non-shmem) FS",
                  "message": "mm,thp: add read-only THP support for (non-shmem) FS\n\nThis patch is (hopefully) the first step to enable THP for non-shmem\nfilesystems.\n\nThis patch enables an application to put part of its text sections to THP\nvia madvise, for example:\n\n    madvise((void *)0x600000, 0x200000, MADV_HUGEPAGE);\n\nWe tried to reuse the logic for THP on tmpfs.\n\nCurrently, write is not supported for non-shmem THP.  khugepaged will only\nprocess vma with VM_DENYWRITE.  sys_mmap() ignores VM_DENYWRITE requests\n(see ksys_mmap_pgoff).  The only way to create vma with VM_DENYWRITE is\nexecve().  This requirement limits non-shmem THP to text sections.\n\nThe next patch will handle writes, which would only happen when the all\nthe vmas with VM_DENYWRITE are unmapped.\n\nAn EXPERIMENTAL config, READ_ONLY_THP_FOR_FS, is added to gate this\nfeature.\n\n[songliubraving@fb.com: fix build without CONFIG_SHMEM]\n  Link: http://lkml.kernel.org/r/F53407FB-96CC-42E8-9862-105C92CC2B98@fb.com\n[songliubraving@fb.com: fix double unlock in collapse_file()]\n  Link: http://lkml.kernel.org/r/B960CBFA-8EFC-4DA4-ABC5-1977FFF2CA57@fb.com\nLink: http://lkml.kernel.org/r/20190801184244.3169074-7-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Rik van Riel <riel@surriel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Stephen Rothwell <sfr@canb.auug.org.au>\nCc: Dan Carpenter <dan.carpenter@oracle.com>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:38:00.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "khugepaged: rename collapse_shmem() and khugepaged_scan_shmem()",
                  "message": "khugepaged: rename collapse_shmem() and khugepaged_scan_shmem()\n\nNext patch will add khugepaged support of non-shmem files.  This patch\nrenames these two functions to reflect the new functionality:\n\n    collapse_shmem()        =>  collapse_file()\n    khugepaged_scan_shmem() =>  khugepaged_scan_file()\n\nLink: http://lkml.kernel.org/r/20190801184244.3169074-6-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Rik van Riel <riel@surriel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:37:57.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm,thp: stats for file backed THP",
                  "message": "mm,thp: stats for file backed THP\n\nIn preparation for non-shmem THP, this patch adds a few stats and exposes\nthem in /proc/meminfo, /sys/bus/node/devices/<node>/meminfo, and\n/proc/<pid>/task/<tid>/smaps.\n\nThis patch is mostly a rewrite of Kirill A.  Shutemov's earlier version:\nhttps://lkml.kernel.org/r/20170126115819.58875-5-kirill.shutemov@linux.intel.com/\n\nLink: http://lkml.kernel.org/r/20190801184244.3169074-5-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Rik van Riel <riel@surriel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:37:54.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "filemap: update offset check in filemap_fault()",
                  "message": "filemap: update offset check in filemap_fault()\n\nWith THP, current check of offset:\n\n    VM_BUG_ON_PAGE(page->index != offset, page);\n\nis no longer accurate. Update it to:\n\n    VM_BUG_ON_PAGE(page_to_pgoff(page) != offset, page);\n\nLink: http://lkml.kernel.org/r/20190801184244.3169074-4-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Rik van Riel <riel@surriel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:37:50.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "filemap: check compound_head(page)->mapping in pagecache_get_page()",
                  "message": "filemap: check compound_head(page)->mapping in pagecache_get_page()\n\nSimilar to previous patch, pagecache_get_page() avoids race condition with\ntruncate by checking page->mapping == mapping.  This does not work for\ncompound pages.  This patch let it check compound_head(page)->mapping\ninstead.\n\nLink: http://lkml.kernel.org/r/20190801184244.3169074-3-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nSuggested-by: Johannes Weiner <hannes@cmpxchg.org>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nCc: Rik van Riel <riel@surriel.com>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:37:47.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "filemap: check compound_head(page)->mapping in filemap_fault()",
                  "message": "filemap: check compound_head(page)->mapping in filemap_fault()\n\nPatch series \"Enable THP for text section of non-shmem files\", v10;\n\nThis patchset follows up discussion at LSF/MM 2019.  The motivation is to\nput text section of an application in THP, and thus reduces iTLB miss rate\nand improves performance.  Both Facebook and Oracle showed strong\ninterests to this feature.\n\nTo make reviews easier, this set aims a mininal valid product.  Current\nversion of the work does not have any changes to file system specific\ncode.  This comes with some limitations (discussed later).\n\nThis set enables an application to \"hugify\" its text section by simply\nrunning something like:\n\n          madvise(0x600000, 0x80000, MADV_HUGEPAGE);\n\nBefore this call, the /proc/<pid>/maps looks like:\n\n    00400000-074d0000 r-xp 00000000 00:27 2006927     app\n\nAfter this call, part of the text section is split out and mapped to\nTHP:\n\n    00400000-00425000 r-xp 00000000 00:27 2006927     app\n    00600000-00e00000 r-xp 00200000 00:27 2006927     app   <<< on THP\n    00e00000-074d0000 r-xp 00a00000 00:27 2006927     app\n\nLimitations:\n\n1. This only works for text section (vma with VM_DENYWRITE).\n2. Original limitation #2 is removed in v3.\n\nWe gated this feature with an experimental config, READ_ONLY_THP_FOR_FS.\nOnce we get better support on the write path, we can remove the config and\nenable it by default.\n\nTested cases:\n1. Tested with btrfs and ext4.\n2. Tested with real work application (memcache like caching service).\n3. Tested with \"THP aware uprobe\":\n   https://patchwork.kernel.org/project/linux-mm/list/?series=131339\n\nThis patch (of 7):\n\nCurrently, filemap_fault() avoids race condition with truncate by checking\npage->mapping == mapping.  This does not work for compound pages.  This\npatch let it check compound_head(page)->mapping instead.\n\nLink: http://lkml.kernel.org/r/20190801184244.3169074-2-songliubraving@fb.com\nSigned-off-by: Song Liu <songliubraving@fb.com>\nAcked-by: Rik van Riel <riel@surriel.com>\nAcked-by: Kirill A. Shutemov <kirill.shutemov@linux.intel.com>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: William Kucharski <william.kucharski@oracle.com>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI2MjgzMDQ=",
                      "login": "liu-song-6"
                    },
                    "name": "Song Liu",
                    "email": "songliubraving@fb.com",
                    "date": "2019-09-23T15:37:44.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "thp: update split_huge_page_pmd() comment",
                  "message": "thp: update split_huge_page_pmd() comment\n\nAccording to 78ddc5347341 (\"thp: rename split_huge_page_pmd() to\nsplit_huge_pmd()\"), update related comment.\n\nLink: http://lkml.kernel.org/r/20190731033406.185285-1-wangkefeng.wang@huawei.com\nSigned-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>\nCc: \"Kirill A . Shutemov\" <kirill.shutemov@linux.intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Kefeng Wang",
                    "email": "wangkefeng.wang@huawei.com",
                    "date": "2019-09-23T15:37:41.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/migrate.c: clean up useless code in migrate_vma_collect_pmd()",
                  "message": "mm/migrate.c: clean up useless code in migrate_vma_collect_pmd()\n\nRemove unused 'pfn' variable.\n\nLink: http://lkml.kernel.org/r/1565167272-21453-1-git-send-email-kernelfans@gmail.com\nSigned-off-by: Pingfan Liu <kernelfans@gmail.com>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nReviewed-by: Ralph Campbell <rcampbell@nvidia.com>\nCc: \"Jérôme Glisse\" <jglisse@redhat.com>\nCc: Mel Gorman <mgorman@techsingularity.net>\nCc: Jan Kara <jack@suse.cz>\nCc: \"Kirill A. Shutemov\" <kirill.shutemov@linux.intel.com>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Mike Kravetz <mike.kravetz@oracle.com>\nCc: Andrea Arcangeli <aarcange@redhat.com>\nCc: Matthew Wilcox <willy@infradead.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjk2OTExMzE=",
                      "login": "liupingfan"
                    },
                    "name": "Pingfan Liu",
                    "email": "kernelfans@gmail.com",
                    "date": "2019-09-23T15:37:38.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "hugetlbfs: don't retry when pool page allocations start to fail",
                  "message": "hugetlbfs: don't retry when pool page allocations start to fail\n\nWhen allocating hugetlbfs pool pages via /proc/sys/vm/nr_hugepages, the\npages will be interleaved between all nodes of the system.  If nodes are\nnot equal, it is quite possible for one node to fill up before the others.\nWhen this happens, the code still attempts to allocate pages from the\nfull node.  This results in calls to direct reclaim and compaction which\nslow things down considerably.\n\nWhen allocating pool pages, note the state of the previous allocation for\neach node.  If previous allocation failed, do not use the aggressive retry\nalgorithm on successive attempts.  The allocation will still succeed if\nthere is memory available, but it will not try as hard to free up memory.\n\nLink: http://lkml.kernel.org/r/20190806014744.15446-5-mike.kravetz@oracle.com\nSigned-off-by: Mike Kravetz <mike.kravetz@oracle.com>\nAcked-by: Vlastimil Babka <vbabka@suse.cz>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Mike Kravetz",
                    "email": "mike.kravetz@oracle.com",
                    "date": "2019-09-23T15:37:35.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm, compaction: raise compaction priority after it withdrawns",
                  "message": "mm, compaction: raise compaction priority after it withdrawns\n\nMike Kravetz reports that \"hugetlb allocations could stall for minutes or\nhours when should_compact_retry() would return true more often then it\nshould.  Specifically, this was in the case where compact_result was\nCOMPACT_DEFERRED and COMPACT_PARTIAL_SKIPPED and no progress was being\nmade.\"\n\nThe problem is that the compaction_withdrawn() test in\nshould_compact_retry() includes compaction outcomes that are only possible\non low compaction priority, and results in a retry without increasing the\npriority.  This may result in furter reclaim, and more incomplete\ncompaction attempts.\n\nWith this patch, compaction priority is raised when possible, or\nshould_compact_retry() returns false.\n\nThe COMPACT_SKIPPED result doesn't really fit together with the other\noutcomes in compaction_withdrawn(), as that's a result caused by\ninsufficient order-0 pages, not due to low compaction priority.  With this\npatch, it is moved to a new compaction_needs_reclaim() function, and for\nthat outcome we keep the current logic of retrying if it looks like\nreclaim will be able to help.\n\nLink: http://lkml.kernel.org/r/20190806014744.15446-4-mike.kravetz@oracle.com\nReported-by: Mike Kravetz <mike.kravetz@oracle.com>\nSigned-off-by: Vlastimil Babka <vbabka@suse.cz>\nSigned-off-by: Mike Kravetz <mike.kravetz@oracle.com>\nTested-by: Mike Kravetz <mike.kravetz@oracle.com>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjkzMjE4Nzg=",
                      "login": "tehcaster"
                    },
                    "name": "Vlastimil Babka",
                    "email": "vbabka@suse.cz",
                    "date": "2019-09-23T15:37:32.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm, reclaim: cleanup should_continue_reclaim()",
                  "message": "mm, reclaim: cleanup should_continue_reclaim()\n\nAfter commit \"mm, reclaim: make should_continue_reclaim perform dryrun\ndetection\", closer look at the function shows, that nr_reclaimed == 0\nmeans the function will always return false.  And since non-zero\nnr_reclaimed implies non_zero nr_scanned, testing nr_scanned serves no\npurpose, and so does the testing for __GFP_RETRY_MAYFAIL.\n\nThis patch thus cleans up the function to test only !nr_reclaimed upfront,\nand remove the __GFP_RETRY_MAYFAIL test and nr_scanned parameter\ncompletely.  Comment is also updated, explaining that approximating \"full\nLRU list has been scanned\" with nr_scanned == 0 didn't really work.\n\nLink: http://lkml.kernel.org/r/20190806014744.15446-3-mike.kravetz@oracle.com\nSigned-off-by: Vlastimil Babka <vbabka@suse.cz>\nSigned-off-by: Mike Kravetz <mike.kravetz@oracle.com>\nAcked-by: Mike Kravetz <mike.kravetz@oracle.com>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjkzMjE4Nzg=",
                      "login": "tehcaster"
                    },
                    "name": "Vlastimil Babka",
                    "email": "vbabka@suse.cz",
                    "date": "2019-09-23T15:37:29.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm, reclaim: make should_continue_reclaim perform dryrun detection",
                  "message": "mm, reclaim: make should_continue_reclaim perform dryrun detection\n\nPatch series \"address hugetlb page allocation stalls\", v2.\n\nAllocation of hugetlb pages via sysctl or procfs can stall for minutes or\nhours.  A simple example on a two node system with 8GB of memory is as\nfollows:\n\necho 4096 > /sys/devices/system/node/node1/hugepages/hugepages-2048kB/nr_hugepages\necho 4096 > /proc/sys/vm/nr_hugepages\n\nObviously, both allocation attempts will fall short of their 8GB goal.\nHowever, one or both of these commands may stall and not be interruptible.\nThe issues were initially discussed in mail thread [1] and RFC code at\n[2].\n\nThis series addresses the issues causing the stalls.  There are two\ndistinct fixes, a cleanup, and an optimization.  The reclaim patch by\nHillf and compaction patch by Vlasitmil address corner cases in their\nrespective areas.  hugetlb page allocation could stall due to either of\nthese issues.  Vlasitmil added a cleanup patch after Hillf's\nmodifications.  The hugetlb patch by Mike is an optimization suggested\nduring the debug and development process.\n\n[1] http://lkml.kernel.org/r/d38a095e-dc39-7e82-bb76-2c9247929f07@oracle.com\n[2] http://lkml.kernel.org/r/20190724175014.9935-1-mike.kravetz@oracle.com\n\nThis patch (of 4):\n\nAddress the issue of should_continue_reclaim returning true too often for\n__GFP_RETRY_MAYFAIL attempts when !nr_reclaimed and nr_scanned.  This was\nobserved during hugetlb page allocation causing stalls for minutes or\nhours.\n\nWe can stop reclaiming pages if compaction reports it can make a progress.\nThere might be side-effects for other high-order allocations that would\npotentially benefit from reclaiming more before compaction so that they\nwould be faster and less likely to stall.  However, the consequences of\npremature/over-reclaim are considered worse.\n\nWe can also bail out of reclaiming pages if we know that there are not\nenough inactive lru pages left to satisfy the costly allocation.\n\nWe can give up reclaiming pages too if we see dryrun occur, with the\ncertainty of plenty of inactive pages.  IOW with dryrun detected, we are\nsure we have reclaimed as many pages as we could.\n\nLink: http://lkml.kernel.org/r/20190806014744.15446-2-mike.kravetz@oracle.com\nSigned-off-by: Hillf Danton <hdanton@sina.com>\nSigned-off-by: Mike Kravetz <mike.kravetz@oracle.com>\nTested-by: Mike Kravetz <mike.kravetz@oracle.com>\nAcked-by: Mel Gorman <mgorman@suse.de>\nAcked-by: Vlastimil Babka <vbabka@suse.cz>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@kernel.org>\nCc: Vlastimil Babka <vbabka@suse.cz>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Hillf Danton",
                    "email": "hdanton@sina.com",
                    "date": "2019-09-23T15:37:26.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "memcg, kmem: deprecate kmem.limit_in_bytes",
                  "message": "memcg, kmem: deprecate kmem.limit_in_bytes\n\nCgroup v1 memcg controller has exposed a dedicated kmem limit to users\nwhich turned out to be really a bad idea because there are paths which\ncannot shrink the kernel memory usage enough to get below the limit (e.g.\nbecause the accounted memory is not reclaimable).  There are cases when\nthe failure is even not allowed (e.g.  __GFP_NOFAIL).  This means that the\nkmem limit is in excess to the hard limit without any way to shrink and\nthus completely useless.  OOM killer cannot be invoked to handle the\nsituation because that would lead to a premature oom killing.\n\nAs a result many places might see ENOMEM returning from kmalloc and result\nin unexpected errors.  E.g.  a global OOM killer when there is a lot of\nfree memory because ENOMEM is translated into VM_FAULT_OOM in #PF path and\ntherefore pagefault_out_of_memory would result in OOM killer.\n\nPlease note that the kernel memory is still accounted to the overall limit\nalong with the user memory so removing the kmem specific limit should\nstill allow to contain kernel memory consumption.  Unlike the kmem one,\nthough, it invokes memory reclaim and targeted memcg oom killing if\nnecessary.\n\nStart the deprecation process by crying to the kernel log.  Let's see\nwhether there are relevant usecases and simply return to EINVAL in the\nsecond stage if nobody complains in few releases.\n\n[akpm@linux-foundation.org: tweak documentation text]\nLink: http://lkml.kernel.org/r/20190911151612.GI4023@dhcp22.suse.cz\nSigned-off-by: Michal Hocko <mhocko@suse.com>\nReviewed-by: Shakeel Butt <shakeelb@google.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nCc: Andrey Ryabinin <aryabinin@virtuozzo.com>\nCc: Thomas Lindroth <thomas.lindroth@gmail.com>\nCc: Tetsuo Handa <penguin-kernel@i-love.sakura.ne.jp>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Michal Hocko",
                    "email": "mhocko@suse.com",
                    "date": "2019-09-23T15:37:22.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memcontrol.c: fix a -Wunused-function warning",
                  "message": "mm/memcontrol.c: fix a -Wunused-function warning\n\nmem_cgroup_id_get() was introduced in commit 73f576c04b94 (\"mm:memcontrol:\nfix cgroup creation failure after many small jobs\").\n\nLater, it no longer has any user since the commits,\n\n1f47b61fb407 (\"mm: memcontrol: fix swap counter leak on swapout from offline cgroup\")\n58fa2a5512d9 (\"mm: memcontrol: add sanity checks for memcg->id.ref on get/put\")\n\nso safe to remove it.\n\nLink: http://lkml.kernel.org/r/1568648453-5482-1-git-send-email-cai@lca.pw\nSigned-off-by: Qian Cai <cai@lca.pw>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjUwNzA4MTYx",
                      "login": "cailca"
                    },
                    "name": "Qian Cai",
                    "email": "cai@lca.pw",
                    "date": "2019-09-23T15:37:19.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm, oom: consider present pages for the node size",
                  "message": "mm, oom: consider present pages for the node size\n\nconstrained_alloc() calculates the size of the oom domain by using\nnode_spanned_pages which is incorrect because this is the full range of\nthe physical memory range that the numa node occupies rather than the\nmemory that backs that range which is represented by node_present_pages.\n\nSparsely populated nodes (e.g.  after memory hot remove or simply sparse\ndue to memory layout) can have really a large difference between the two.\nThis shouldn't really cause any real user observable problems because the\noom calculates a ratio against totalpages and used memory cannot exceed\npresent pages but it is confusing and wrong from code point of view.\n\nLink: http://lkml.kernel.org/r/20190829163443.899-1-mhocko@kernel.org\nSigned-off-by: Michal Hocko <mhocko@suse.com>\nReported-by: David Hildenbrand <david@redhat.com>\nReviewed-by: David Hildenbrand <david@redhat.com>\nAcked-by: David Rientjes <rientjes@google.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Michal Hocko",
                    "email": "mhocko@suse.com",
                    "date": "2019-09-23T15:37:16.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/oom_kill.c: fix oom_cpuset_eligible() comment",
                  "message": "mm/oom_kill.c: fix oom_cpuset_eligible() comment\n\nCommit ac311a14c682 (\"oom: decouple mems_allowed from\noom_unkillable_task\") changed has_intersects_mems_allowed() to\noom_cpuset_eligible(), but didn't change the comment.\n\nLink: http://lkml.kernel.org/r/1566959929-10638-1-git-send-email-wang.yi59@zte.com.cn\nSigned-off-by: Yi Wang <wang.yi59@zte.com.cn>\nAcked-by: Michal Hocko <mhocko@suse.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjI1ODUzNDI=",
                      "login": "up2wing"
                    },
                    "name": "Yi Wang",
                    "email": "wang.yi59@zte.com.cn",
                    "date": "2019-09-23T15:37:14.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/oom: add oom_score_adj and pgtables to Killed process message",
                  "message": "mm/oom: add oom_score_adj and pgtables to Killed process message\n\nFor an OOM event: print oom_score_adj value for the OOM Killed process to\ndocument what the oom score adjust value was at the time the process was\nOOM Killed.  The adjustment value can be set by user code and it affects\nthe resulting oom_score so it is used to influence kill process selection.\n\nWhen eligible tasks are not printed (sysctl oom_dump_tasks = 0) printing\nthis value is the only documentation of the value for the process being\nkilled.  Having this value on the Killed process message is useful to\ndocument if a miscconfiguration occurred or to confirm that the\noom_score_adj configuration applies as expected.\n\nAn example which illustates both misconfiguration and validation that the\noom_score_adj was applied as expected is:\n\nAug 14 23:00:02 testserver kernel: Out of memory: Killed process 2692\n (systemd-udevd) total-vm:1056800kB, anon-rss:1052760kB, file-rss:4kB,\n shmem-rss:0kB pgtables:22kB oom_score_adj:1000\n\nThe systemd-udevd is a critical system application that should have an\noom_score_adj of -1000.  It was miconfigured to have a adjustment of 1000\nmaking it a highly favored OOM kill target process.  The output documents\nboth the misconfiguration and the fact that the process was correctly\ntargeted by OOM due to the miconfiguration.  This can be quite helpful for\ntriage and problem determination.\n\nThe addition of the pgtables_bytes shows page table usage by the process\nand is a useful measure of the memory size of the process.\n\nLink: http://lkml.kernel.org/r/20190822173157.1569-1-echron@arista.com\nSigned-off-by: Edward Chron <echron@arista.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nAcked-by: David Rientjes <rientjes@google.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Edward Chron",
                    "email": "echron@arista.com",
                    "date": "2019-09-23T15:37:11.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "memcg, oom: don't require __GFP_FS when invoking memcg OOM killer",
                  "message": "memcg, oom: don't require __GFP_FS when invoking memcg OOM killer\n\nMasoud Sharbiani noticed that commit 29ef680ae7c21110 (\"memcg, oom: move\nout_of_memory back to the charge path\") broke memcg OOM called from\n__xfs_filemap_fault() path.  It turned out that try_charge() is retrying\nforever without making forward progress because mem_cgroup_oom(GFP_NOFS)\ncannot invoke the OOM killer due to commit 3da88fb3bacfaa33 (\"mm, oom:\nmove GFP_NOFS check to out_of_memory\").\n\nAllowing forced charge due to being unable to invoke memcg OOM killer will\nlead to global OOM situation.  Also, just returning -ENOMEM will be risky\nbecause OOM path is lost and some paths (e.g.  get_user_pages()) will leak\n-ENOMEM.  Therefore, invoking memcg OOM killer (despite GFP_NOFS) will be\nthe only choice we can choose for now.\n\nUntil 29ef680ae7c21110, we were able to invoke memcg OOM killer when\nGFP_KERNEL reclaim failed [1].  But since 29ef680ae7c21110, we need to\ninvoke memcg OOM killer when GFP_NOFS reclaim failed [2].  Although in the\npast we did invoke memcg OOM killer for GFP_NOFS [3], we might get\npre-mature memcg OOM reports due to this patch.\n\n[1]\n\n leaker invoked oom-killer: gfp_mask=0x6200ca(GFP_HIGHUSER_MOVABLE), nodemask=(null), order=0, oom_score_adj=0\n CPU: 0 PID: 2746 Comm: leaker Not tainted 4.18.0+ #19\n Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 04/13/2018\n Call Trace:\n  dump_stack+0x63/0x88\n  dump_header+0x67/0x27a\n  ? mem_cgroup_scan_tasks+0x91/0xf0\n  oom_kill_process+0x210/0x410\n  out_of_memory+0x10a/0x2c0\n  mem_cgroup_out_of_memory+0x46/0x80\n  mem_cgroup_oom_synchronize+0x2e4/0x310\n  ? high_work_func+0x20/0x20\n  pagefault_out_of_memory+0x31/0x76\n  mm_fault_error+0x55/0x115\n  ? handle_mm_fault+0xfd/0x220\n  __do_page_fault+0x433/0x4e0\n  do_page_fault+0x22/0x30\n  ? page_fault+0x8/0x30\n  page_fault+0x1e/0x30\n RIP: 0033:0x4009f0\n Code: 03 00 00 00 e8 71 fd ff ff 48 83 f8 ff 49 89 c6 74 74 48 89 c6 bf c0 0c 40 00 31 c0 e8 69 fd ff ff 45 85 ff 7e 21 31 c9 66 90 <41> 0f be 14 0e 01 d3 f7 c1 ff 0f 00 00 75 05 41 c6 04 0e 2a 48 83\n RSP: 002b:00007ffe29ae96f0 EFLAGS: 00010206\n RAX: 000000000000001b RBX: 0000000000000000 RCX: 0000000001ce1000\n RDX: 0000000000000000 RSI: 000000007fffffe5 RDI: 0000000000000000\n RBP: 000000000000000c R08: 0000000000000000 R09: 00007f94be09220d\n R10: 0000000000000002 R11: 0000000000000246 R12: 00000000000186a0\n R13: 0000000000000003 R14: 00007f949d845000 R15: 0000000002800000\n Task in /leaker killed as a result of limit of /leaker\n memory: usage 524288kB, limit 524288kB, failcnt 158965\n memory+swap: usage 0kB, limit 9007199254740988kB, failcnt 0\n kmem: usage 2016kB, limit 9007199254740988kB, failcnt 0\n Memory cgroup stats for /leaker: cache:844KB rss:521136KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:132KB writeback:0KB inactive_anon:0KB active_anon:521224KB inactive_file:1012KB active_file:8KB unevictable:0KB\n Memory cgroup out of memory: Kill process 2746 (leaker) score 998 or sacrifice child\n Killed process 2746 (leaker) total-vm:536704kB, anon-rss:521176kB, file-rss:1208kB, shmem-rss:0kB\n oom_reaper: reaped process 2746 (leaker), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB\n\n[2]\n\n leaker invoked oom-killer: gfp_mask=0x600040(GFP_NOFS), nodemask=(null), order=0, oom_score_adj=0\n CPU: 1 PID: 2746 Comm: leaker Not tainted 4.18.0+ #20\n Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 04/13/2018\n Call Trace:\n  dump_stack+0x63/0x88\n  dump_header+0x67/0x27a\n  ? mem_cgroup_scan_tasks+0x91/0xf0\n  oom_kill_process+0x210/0x410\n  out_of_memory+0x109/0x2d0\n  mem_cgroup_out_of_memory+0x46/0x80\n  try_charge+0x58d/0x650\n  ? __radix_tree_replace+0x81/0x100\n  mem_cgroup_try_charge+0x7a/0x100\n  __add_to_page_cache_locked+0x92/0x180\n  add_to_page_cache_lru+0x4d/0xf0\n  iomap_readpages_actor+0xde/0x1b0\n  ? iomap_zero_range_actor+0x1d0/0x1d0\n  iomap_apply+0xaf/0x130\n  iomap_readpages+0x9f/0x150\n  ? iomap_zero_range_actor+0x1d0/0x1d0\n  xfs_vm_readpages+0x18/0x20 [xfs]\n  read_pages+0x60/0x140\n  __do_page_cache_readahead+0x193/0x1b0\n  ondemand_readahead+0x16d/0x2c0\n  page_cache_async_readahead+0x9a/0xd0\n  filemap_fault+0x403/0x620\n  ? alloc_set_pte+0x12c/0x540\n  ? _cond_resched+0x14/0x30\n  __xfs_filemap_fault+0x66/0x180 [xfs]\n  xfs_filemap_fault+0x27/0x30 [xfs]\n  __do_fault+0x19/0x40\n  __handle_mm_fault+0x8e8/0xb60\n  handle_mm_fault+0xfd/0x220\n  __do_page_fault+0x238/0x4e0\n  do_page_fault+0x22/0x30\n  ? page_fault+0x8/0x30\n  page_fault+0x1e/0x30\n RIP: 0033:0x4009f0\n Code: 03 00 00 00 e8 71 fd ff ff 48 83 f8 ff 49 89 c6 74 74 48 89 c6 bf c0 0c 40 00 31 c0 e8 69 fd ff ff 45 85 ff 7e 21 31 c9 66 90 <41> 0f be 14 0e 01 d3 f7 c1 ff 0f 00 00 75 05 41 c6 04 0e 2a 48 83\n RSP: 002b:00007ffda45c9290 EFLAGS: 00010206\n RAX: 000000000000001b RBX: 0000000000000000 RCX: 0000000001a1e000\n RDX: 0000000000000000 RSI: 000000007fffffe5 RDI: 0000000000000000\n RBP: 000000000000000c R08: 0000000000000000 R09: 00007f6d061ff20d\n R10: 0000000000000002 R11: 0000000000000246 R12: 00000000000186a0\n R13: 0000000000000003 R14: 00007f6ce59b2000 R15: 0000000002800000\n Task in /leaker killed as a result of limit of /leaker\n memory: usage 524288kB, limit 524288kB, failcnt 7221\n memory+swap: usage 0kB, limit 9007199254740988kB, failcnt 0\n kmem: usage 1944kB, limit 9007199254740988kB, failcnt 0\n Memory cgroup stats for /leaker: cache:3632KB rss:518232KB rss_huge:0KB shmem:0KB mapped_file:0KB dirty:0KB writeback:0KB inactive_anon:0KB active_anon:518408KB inactive_file:3908KB active_file:12KB unevictable:0KB\n Memory cgroup out of memory: Kill process 2746 (leaker) score 992 or sacrifice child\n Killed process 2746 (leaker) total-vm:536704kB, anon-rss:518264kB, file-rss:1188kB, shmem-rss:0kB\n oom_reaper: reaped process 2746 (leaker), now anon-rss:0kB, file-rss:0kB, shmem-rss:0kB\n\n[3]\n\n leaker invoked oom-killer: gfp_mask=0x50, order=0, oom_score_adj=0\n leaker cpuset=/ mems_allowed=0\n CPU: 1 PID: 3206 Comm: leaker Not tainted 3.10.0-957.27.2.el7.x86_64 #1\n Hardware name: VMware, Inc. VMware Virtual Platform/440BX Desktop Reference Platform, BIOS 6.00 04/13/2018\n Call Trace:\n  [<ffffffffaf364147>] dump_stack+0x19/0x1b\n  [<ffffffffaf35eb6a>] dump_header+0x90/0x229\n  [<ffffffffaedbb456>] ? find_lock_task_mm+0x56/0xc0\n  [<ffffffffaee32a38>] ? try_get_mem_cgroup_from_mm+0x28/0x60\n  [<ffffffffaedbb904>] oom_kill_process+0x254/0x3d0\n  [<ffffffffaee36c36>] mem_cgroup_oom_synchronize+0x546/0x570\n  [<ffffffffaee360b0>] ? mem_cgroup_charge_common+0xc0/0xc0\n  [<ffffffffaedbc194>] pagefault_out_of_memory+0x14/0x90\n  [<ffffffffaf35d072>] mm_fault_error+0x6a/0x157\n  [<ffffffffaf3717c8>] __do_page_fault+0x3c8/0x4f0\n  [<ffffffffaf371925>] do_page_fault+0x35/0x90\n  [<ffffffffaf36d768>] page_fault+0x28/0x30\n Task in /leaker killed as a result of limit of /leaker\n memory: usage 524288kB, limit 524288kB, failcnt 20628\n memory+swap: usage 524288kB, limit 9007199254740988kB, failcnt 0\n kmem: usage 0kB, limit 9007199254740988kB, failcnt 0\n Memory cgroup stats for /leaker: cache:840KB rss:523448KB rss_huge:0KB mapped_file:0KB swap:0KB inactive_anon:0KB active_anon:523448KB inactive_file:464KB active_file:376KB unevictable:0KB\n Memory cgroup out of memory: Kill process 3206 (leaker) score 970 or sacrifice child\n Killed process 3206 (leaker) total-vm:536692kB, anon-rss:523304kB, file-rss:412kB, shmem-rss:0kB\n\nBisected by Masoud Sharbiani.\n\nLink: http://lkml.kernel.org/r/cbe54ed1-b6ba-a056-8899-2dc42526371d@i-love.sakura.ne.jp\nFixes: 3da88fb3bacfaa33 (\"mm, oom: move GFP_NOFS check to out_of_memory\") [necessary after 29ef680ae7c21110]\nSigned-off-by: Tetsuo Handa <penguin-kernel@I-love.SAKURA.ne.jp>\nReported-by: Masoud Sharbiani <msharbiani@apple.com>\nTested-by: Masoud Sharbiani <msharbiani@apple.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: David Rientjes <rientjes@google.com>\nCc: <stable@vger.kernel.org>\t[4.19+]\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Tetsuo Handa",
                    "email": "penguin-kernel@i-love.sakura.ne.jp",
                    "date": "2019-09-23T15:37:08.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/oom_kill.c: add task UID to info message on an oom kill",
                  "message": "mm/oom_kill.c: add task UID to info message on an oom kill\n\nIn the event of an oom kill, useful information about the killed process\nis printed to dmesg.  Users, especially system administrators, will find\nit useful to immediately see the UID of the process.\n\nWe already print uid when dumping eligible tasks so it is not overly hard\nto find that information in the oom report.  However this information is\nunavailable when dumping of eligible tasks is disabled.\n\nIn the following example, abuse_the_ram is the name of a program that\nattempts to iteratively allocate all available memory until it is stopped\nby force.\n\nCurrent message:\n\nOut of memory: Killed process 35389 (abuse_the_ram)\ntotal-vm:133718232kB, anon-rss:129624980kB, file-rss:0kB,\nshmem-rss:0kB\n\nPatched message:\n\nOut of memory: Killed process 2739 (abuse_the_ram),\ntotal-vm:133880028kB, anon-rss:129754836kB, file-rss:0kB,\nshmem-rss:0kB, UID:0\n\n[akpm@linux-foundation.org: s/UID %d/UID:%u/ in printk]\nLink: http://lkml.kernel.org/r/1560362273-534-1-git-send-email-jsavitz@redhat.com\nSigned-off-by: Joel Savitz <jsavitz@redhat.com>\nSuggested-by: David Rientjes <rientjes@google.com>\nAcked-by: Rafael Aquini <aquini@redhat.com>\nCc: Michal Hocko <mhocko@kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE5MDk4NDE=",
                      "login": "theyoyojo"
                    },
                    "name": "Joel Savitz",
                    "email": "jsavitz@redhat.com",
                    "date": "2019-09-23T15:37:04.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/mempolicy.c: remove unnecessary nodemask check in kernel_migrate_p…",
                  "message": "mm/mempolicy.c: remove unnecessary nodemask check in kernel_migrate_pages()\n\n1) task_nodes = cpuset_mems_allowed(current);\n   -> cpuset_mems_allowed() guaranteed to return some non-empty\n      subset of node_states[N_MEMORY].\n\n2) nodes_and(*new, *new, task_nodes);\n   -> after nodes_and(), the 'new' should be empty or appropriate\n      nodemask(online node and with memory).\n\nAfter 1) and 2), we could remove unnecessary check whether the 'new'\nAND node_states[N_MEMORY] is empty.\n\nLink: http://lkml.kernel.org/r/20190806023634.55356-1-wangkefeng.wang@huawei.com\nSigned-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>\nAcked-by: Vlastimil Babka <vbabka@suse.cz>\nCc: Andrea Arcangeli <aarcange@redhat.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Oscar Salvador <osalvador@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Kefeng Wang",
                    "email": "wangkefeng.wang@huawei.com",
                    "date": "2019-09-23T15:37:01.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/compaction.c: remove unnecessary zone parameter in isolate_migrate…",
                  "message": "mm/compaction.c: remove unnecessary zone parameter in isolate_migratepages()\n\nLike commit 40cacbcb3240 (\"mm, compaction: remove unnecessary zone\nparameter in some instances\"), remove unnecessary zone parameter.\n\nNo functional change.\n\nLink: http://lkml.kernel.org/r/20190806151616.21107-1-lpf.vector@gmail.com\nSigned-off-by: Pengfei Li <lpf.vector@gmail.com>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nAcked-by: Vlastimil Babka <vbabka@suse.cz>\nCc: Mel Gorman <mgorman@techsingularity.net>\nCc: Qian Cai <cai@lca.pw>\nCc: Andrey Ryabinin <aryabinin@virtuozzo.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEyOTEyNTE0",
                      "login": "Twistack"
                    },
                    "name": "Pengfei Li",
                    "email": "lpf.vector@gmail.com",
                    "date": "2019-09-23T15:36:58.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/compaction.c: clear total_{migrate,free}_scanned before scanning a…",
                  "message": "mm/compaction.c: clear total_{migrate,free}_scanned before scanning a new zone\n\ntotal_{migrate,free}_scanned will be added to COMPACTMIGRATE_SCANNED and\nCOMPACTFREE_SCANNED in compact_zone().  We should clear them before\nscanning a new zone.  In the proc triggered compaction, we forgot clearing\nthem.\n\n[laoar.shao@gmail.com: introduce a helper compact_zone_counters_init()]\n  Link: http://lkml.kernel.org/r/1563869295-25748-1-git-send-email-laoar.shao@gmail.com\n[akpm@linux-foundation.org: expand compact_zone_counters_init() into its single callsite, per mhocko]\n[vbabka@suse.cz: squash compact_zone() list_head init as well]\n  Link: http://lkml.kernel.org/r/1fb6f7da-f776-9e42-22f8-bbb79b030b98@suse.cz\n[akpm@linux-foundation.org: kcompactd_do_work(): avoid unnecessary initialization of cc.zone]\nLink: http://lkml.kernel.org/r/1563789275-9639-1-git-send-email-laoar.shao@gmail.com\nFixes: 7f354a548d1c (\"mm, compaction: add vmstats for kcompactd work\")\nSigned-off-by: Yafang Shao <laoar.shao@gmail.com>\nSigned-off-by: Vlastimil Babka <vbabka@suse.cz>\nReviewed-by: Vlastimil Babka <vbabka@suse.cz>\nCc: David Rientjes <rientjes@google.com>\nCc: Yafang Shao <shaoyafang@didiglobal.com>\nCc: Mel Gorman <mgorman@techsingularity.net>\nCc: Michal Hocko <mhocko@suse.com>\nCc: <stable@vger.kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjM4NDMzMTc=",
                      "login": "laoar"
                    },
                    "name": "Yafang Shao",
                    "email": "laoar.shao@gmail.com",
                    "date": "2019-09-23T15:36:54.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "z3fold: fix memory leak in kmem cache",
                  "message": "z3fold: fix memory leak in kmem cache\n\nCurrently there is a leak in init_z3fold_page() -- it allocates handles\nfrom kmem cache even for headless pages, but then they are never used and\nnever freed, so eventually kmem cache may get exhausted.  This patch\nprovides a fix for that.\n\nLink: http://lkml.kernel.org/r/20190917185352.44cf285d3ebd9e64548de5de@gmail.com\nSigned-off-by: Vitaly Wool <vitalywool@gmail.com>\nReported-by: Markus Linnala <markus.linnala@gmail.com>\nTested-by: Markus Linnala <markus.linnala@gmail.com>\nCc: Dan Streetman <ddstreet@ieee.org>\nCc: Henry Burns <henrywolfeburns@gmail.com>\nCc: Shakeel Butt <shakeelb@google.com>\nCc: Vlastimil Babka <vbabka@suse.cz>\nCc: <stable@vger.kernel.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE2MDg2NTgw",
                      "login": "vwool"
                    },
                    "name": "Vitaly Wool",
                    "email": "vitalywool@gmail.com",
                    "date": "2019-09-23T15:36:51.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: silence -Woverride-init/initializer-overrides",
                  "message": "mm: silence -Woverride-init/initializer-overrides\n\nWhen compiling a kernel with W=1, there are several of those warnings due\nto arm64 overriding a field on purpose.  Just disable those warnings for\nboth GCC and Clang of this file, so it will help dig \"gems\" hidden in the\nW=1 warnings by reducing some noises.\n\nmm/init-mm.c:39:2: warning: initializer overrides prior initialization\nof this subobject [-Winitializer-overrides]\n        INIT_MM_CONTEXT(init_mm)\n        ^~~~~~~~~~~~~~~~~~~~~~~~\n./arch/arm64/include/asm/mmu.h:133:9: note: expanded from macro\n'INIT_MM_CONTEXT'\n        .pgd = init_pg_dir,\n               ^~~~~~~~~~~\nmm/init-mm.c:30:10: note: previous initialization is here\n        .pgd            = swapper_pg_dir,\n                          ^~~~~~~~~~~~~~\n\nNote: there is a side project trying to support explicitly allowing\nspecific initializer overrides in Clang, but there is no guarantee it\nwill happen or not.\n\nhttps://github.com/ClangBuiltLinux/linux/issues/639\n\nLink: http://lkml.kernel.org/r/1566920867-27453-1-git-send-email-cai@lca.pw\nSigned-off-by: Qian Cai <cai@lca.pw>\nCc: Nick Desaulniers <ndesaulniers@google.com>\nCc: Masahiro Yamada <yamada.masahiro@socionext.com>\nCc: Mark Rutland <mark.rutland@arm.com>\nCc: Arnd Bergmann <arnd@arndb.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjUwNzA4MTYx",
                      "login": "cailca"
                    },
                    "name": "Qian Cai",
                    "email": "cai@lca.pw",
                    "date": "2019-09-23T15:36:48.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: use CPU_BITS_NONE to initialize init_mm.cpu_bitmask",
                  "message": "mm: use CPU_BITS_NONE to initialize init_mm.cpu_bitmask\n\nReplace open-coded bitmap array initialization of init_mm.cpu_bitmask with\nneat CPU_BITS_NONE macro.\n\nAnd, since init_mm.cpu_bitmask is statically set to zero, there is no way\nto clear it again in start_kernel().\n\nLink: http://lkml.kernel.org/r/1565703815-8584-1-git-send-email-rppt@linux.ibm.com\nSigned-off-by: Mike Rapoport <rppt@linux.ibm.com>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nReviewed-by: David Hildenbrand <david@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Mike Rapoport",
                    "email": "rppt@linux.ibm.com",
                    "date": "2019-09-23T15:36:45.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/vmalloc.c: move 'area->pages' after if statement",
                  "message": "mm/vmalloc.c: move 'area->pages' after if statement\n\nIf !area->pages statement is true where memory allocation fails, area is\nfreed.\n\nIn this case 'area->pages = pages' should not executed.  So move\n'area->pages = pages' after if statement.\n\n[akpm@linux-foundation.org: give area->pages the same treatment]\nLink: http://lkml.kernel.org/r/20190830035716.GA190684@LGEARND20B15\nSigned-off-by: Austin Kim <austindh.kim@gmail.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Uladzislau Rezki (Sony) <urezki@gmail.com>\nCc: Roman Gushchin <guro@fb.com>\nCc: Roman Penyaev <rpenyaev@suse.de>\nCc: Rick Edgecombe <rick.p.edgecombe@intel.com>\nCc: Mike Rapoport <rppt@linux.ibm.com>\nCc: Andrey Ryabinin <aryabinin@virtuozzo.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjU0NzQyMzk0",
                      "login": "austindhkim"
                    },
                    "name": "Austin Kim",
                    "email": "austindh.kim@gmail.com",
                    "date": "2019-09-23T15:36:42.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/vmalloc: modify struct vmap_area to reduce its size",
                  "message": "mm/vmalloc: modify struct vmap_area to reduce its size\n\nObjective\n---------\n\nThe current implementation of struct vmap_area wasted space.\n\nAfter applying this commit, sizeof(struct vmap_area) has been\nreduced from 11 words to 8 words.\n\nDescription\n-----------\n\n1) Pack \"subtree_max_size\", \"vm\" and \"purge_list\".  This is no problem\n   because\n\nA) \"subtree_max_size\" is only used when vmap_area is in \"free\" tree\n\nB) \"vm\" is only used when vmap_area is in \"busy\" tree\n\nC) \"purge_list\" is only used when vmap_area is in vmap_purge_list\n\n2) Eliminate \"flags\".\n\n;Since only one flag VM_VM_AREA is being used, and the same thing can be\ndone by judging whether \"vm\" is NULL, then the \"flags\" can be eliminated.\n\nLink: http://lkml.kernel.org/r/20190716152656.12255-3-lpf.vector@gmail.com\nSigned-off-by: Pengfei Li <lpf.vector@gmail.com>\nSuggested-by: Uladzislau Rezki (Sony) <urezki@gmail.com>\nReviewed-by: Uladzislau Rezki (Sony) <urezki@gmail.com>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Matthew Wilcox <willy@infradead.org>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Oleksiy Avramchenko <oleksiy.avramchenko@sonymobile.com>\nCc: Roman Gushchin <guro@fb.com>\nCc: Steven Rostedt <rostedt@goodmis.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEyOTEyNTE0",
                      "login": "Twistack"
                    },
                    "name": "Pengfei Li",
                    "email": "lpf.vector@gmail.com",
                    "date": "2019-09-23T15:36:39.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/vmalloc: do not keep unpurged areas in the busy tree",
                  "message": "mm/vmalloc: do not keep unpurged areas in the busy tree\n\nThe busy tree can be quite big, even though the area is freed or unmapped\nit still stays there until \"purge\" logic removes it.\n\n1) Optimize and reduce the size of \"busy\" tree by removing a node from\n   it right away as soon as user triggers free paths.  It is possible to\n   do so, because the allocation is done using another augmented tree.\n\nThe vmalloc test driver shows the difference, for example the\n\"fix_size_alloc_test\" is ~11% better comparing with default configuration:\n\nsudo ./test_vmalloc.sh performance\n\n<default>\nSummary: fix_size_alloc_test loops: 1000000 avg: 993985 usec\nSummary: full_fit_alloc_test loops: 1000000 avg: 973554 usec\nSummary: long_busy_list_alloc_test loops: 1000000 avg: 12617652 usec\n<default>\n\n<this patch>\nSummary: fix_size_alloc_test loops: 1000000 avg: 882263 usec\nSummary: full_fit_alloc_test loops: 1000000 avg: 973407 usec\nSummary: long_busy_list_alloc_test loops: 1000000 avg: 12593929 usec\n<this patch>\n\n2) Since the busy tree now contains allocated areas only and does not\n   interfere with lazily free nodes, introduce the new function\n   show_purge_info() that dumps \"unpurged\" areas that is propagated\n   through \"/proc/vmallocinfo\".\n\n3) Eliminate VM_LAZY_FREE flag.\n\nLink: http://lkml.kernel.org/r/20190716152656.12255-2-lpf.vector@gmail.com\nSigned-off-by: Uladzislau Rezki (Sony) <urezki@gmail.com>\nSigned-off-by: Pengfei Li <lpf.vector@gmail.com>\nCc: Roman Gushchin <guro@fb.com>\nCc: Uladzislau Rezki <urezki@gmail.com>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Matthew Wilcox <willy@infradead.org>\nCc: Oleksiy Avramchenko <oleksiy.avramchenko@sonymobile.com>\nCc: Steven Rostedt <rostedt@goodmis.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjExNTM0NQ==",
                      "login": "urezki"
                    },
                    "name": "Uladzislau Rezki (Sony)",
                    "email": "urezki@gmail.com",
                    "date": "2019-09-23T15:36:36.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/sparse.c: remove NULL check in clear_hwpoisoned_pages()",
                  "message": "mm/sparse.c: remove NULL check in clear_hwpoisoned_pages()\n\nThere is no possibility for memmap to be NULL in the current codebase.\n\nThis check was added in commit 95a4774d055c (\"memory-hotplug: update\nmce_bad_pages when removing the memory\") where memmap was originally\ninited to NULL, and only conditionally given a value.\n\nThe code that could have passed a NULL has been removed by commit\nba72b4c8cf60 (\"mm/sparsemem: support sub-section hotplug\"), so there is no\nlonger a possibility that memmap can be NULL.\n\nLink: http://lkml.kernel.org/r/20190829035151.20975-1-alastair@d-silva.org\nSigned-off-by: Alastair D'Silva <alastair@d-silva.org>\nAcked-by: Michal Hocko <mhocko@suse.com>\nReviewed-by: David Hildenbrand <david@redhat.com>\nCc: Mike Rapoport <rppt@linux.ibm.com>\nCc: Wei Yang <richard.weiyang@gmail.com>\nCc: Qian Cai <cai@lca.pw>\nCc: Alexander Duyck <alexander.h.duyck@linux.intel.com>\nCc: Logan Gunthorpe <logang@deltatee.com>\nCc: Baoquan He <bhe@redhat.com>\nCc: Balbir Singh <bsingharora@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE4NjIwNTU=",
                      "login": "deece"
                    },
                    "name": "Alastair D'Silva",
                    "email": "alastair@d-silva.org",
                    "date": "2019-09-23T15:36:33.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/sparse.c: don't manually decrement num_poisoned_pages",
                  "message": "mm/sparse.c: don't manually decrement num_poisoned_pages\n\nUse the function written to do it instead.\n\nLink: http://lkml.kernel.org/r/20190827053656.32191-2-alastair@au1.ibm.com\nSigned-off-by: Alastair D'Silva <alastair@d-silva.org>\nAcked-by: Michal Hocko <mhocko@suse.com>\nReviewed-by: David Hildenbrand <david@redhat.com>\nAcked-by: Mike Rapoport <rppt@linux.ibm.com>\nReviewed-by: Wei Yang <richardw.yang@linux.intel.com>\nReviewed-by: Oscar Salvador <osalvador@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE4NjIwNTU=",
                      "login": "deece"
                    },
                    "name": "Alastair D'Silva",
                    "email": "alastair@d-silva.org",
                    "date": "2019-09-23T15:36:30.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/sparse.c: use __nr_to_section(section_nr) to get mem_section",
                  "message": "mm/sparse.c: use __nr_to_section(section_nr) to get mem_section\n\n__pfn_to_section is defined as __nr_to_section(pfn_to_section_nr(pfn)).\n\nSince we already get section_nr, it is not necessary to get mem_section\nfrom start_pfn. By doing so, we reduce one redundant operation.\n\nLink: http://lkml.kernel.org/r/20190809010242.29797-1-richardw.yang@linux.intel.com\nSigned-off-by: Wei Yang <richardw.yang@linux.intel.com>\nReviewed-by: Anshuman Khandual <anshuman.khandual@arm.com>\nTested-by: Anshuman Khandual <anshuman.khandual@arm.com>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Pavel Tatashin <pasha.tatashin@oracle.com>\nCc: Michal Hocko <mhocko@suse.com>\nCc: David Hildenbrand <david@redhat.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Wei Yang",
                    "email": "richardw.yang@linux.intel.com",
                    "date": "2019-09-23T15:36:27.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/sparse.c: fix ALIGN() without power of 2 in sparse_buffer_alloc()",
                  "message": "mm/sparse.c: fix ALIGN() without power of 2 in sparse_buffer_alloc()\n\nThe size argument passed into sparse_buffer_alloc() has already been\naligned with PAGE_SIZE or PMD_SIZE.\n\nIf the size after aligned is not power of 2 (e.g.  0x480000), the\nPTR_ALIGN() will return wrong value.  Use roundup to round sparsemap_buf\nup to next multiple of size.\n\nLink: http://lkml.kernel.org/r/20190705114826.28586-1-lecopzer.chen@mediatek.com\nSigned-off-by: Lecopzer Chen <lecopzer.chen@mediatek.com>\nSigned-off-by: Mark-PK Tsai <Mark-PK.Tsai@mediatek.com>\nCc: YJ Chiang <yj.chiang@mediatek.com>\nCc: Lecopzer Chen <lecopzer.chen@mediatek.com>\nCc: Pavel Tatashin <pasha.tatashin@oracle.com>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Mike Rapoport <rppt@linux.ibm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Lecopzer Chen",
                    "email": "lecopzer.chen@mediatek.com",
                    "date": "2019-09-23T15:36:24.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/sparse.c: fix memory leak of sparsemap_buf in aligned memory",
                  "message": "mm/sparse.c: fix memory leak of sparsemap_buf in aligned memory\n\nsparse_buffer_alloc(xsize) gets the size of memory from sparsemap_buf\nafter being aligned with the size.  However, the size is at least\nPAGE_ALIGN(sizeof(struct page) * PAGES_PER_SECTION) and usually larger\nthan PAGE_SIZE.\n\nAlso, sparse_buffer_fini() only frees memory between sparsemap_buf and\nsparsemap_buf_end, since sparsemap_buf may be changed by PTR_ALIGN()\nfirst, the aligned space before sparsemap_buf is wasted and no one will\ntouch it.\n\nIn our ARM32 platform (without SPARSEMEM_VMEMMAP)\n  Sparse_buffer_init\n    Reserve d359c000 - d3e9c000 (9M)\n  Sparse_buffer_alloc\n    Alloc   d3a00000 - d3E80000 (4.5M)\n  Sparse_buffer_fini\n    Free    d3e80000 - d3e9c000 (~=100k)\n The reserved memory between d359c000 - d3a00000 (~=4.4M) is unfreed.\n\nIn ARM64 platform (with SPARSEMEM_VMEMMAP)\n\n  sparse_buffer_init\n    Reserve ffffffc07d623000 - ffffffc07f623000 (32M)\n  Sparse_buffer_alloc\n    Alloc   ffffffc07d800000 - ffffffc07f600000 (30M)\n  Sparse_buffer_fini\n    Free    ffffffc07f600000 - ffffffc07f623000 (140K)\n The reserved memory between ffffffc07d623000 - ffffffc07d800000\n (~=1.9M) is unfreed.\n\nLet's explicit free redundant aligned memory.\n\n[arnd@arndb.de: mark sparse_buffer_free as __meminit]\n  Link: http://lkml.kernel.org/r/20190709185528.3251709-1-arnd@arndb.de\nLink: http://lkml.kernel.org/r/20190705114730.28534-1-lecopzer.chen@mediatek.com\nSigned-off-by: Lecopzer Chen <lecopzer.chen@mediatek.com>\nSigned-off-by: Mark-PK Tsai <Mark-PK.Tsai@mediatek.com>\nSigned-off-by: Arnd Bergmann <arnd@arndb.de>\nCc: YJ Chiang <yj.chiang@mediatek.com>\nCc: Lecopzer Chen <lecopzer.chen@mediatek.com>\nCc: Pavel Tatashin <pasha.tatashin@oracle.com>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Mike Rapoport <rppt@linux.ibm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Lecopzer Chen",
                    "email": "lecopzer.chen@mediatek.com",
                    "date": "2019-09-23T15:36:21.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug.c: s/is/if",
                  "message": "mm/memory_hotplug.c: s/is/if\n\nCorrect typo in comment.\n\nLink: http://lkml.kernel.org/r/1568233954-3913-1-git-send-email-jrdr.linux@gmail.com\nSigned-off-by: Souptick Joarder <jrdr.linux@gmail.com>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Souptick Joarder",
                    "email": "jrdr.linux@gmail.com",
                    "date": "2019-09-23T15:36:18.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug: online_pages cannot be 0 in online_pages()",
                  "message": "mm/memory_hotplug: online_pages cannot be 0 in online_pages()\n\nwalk_system_ram_range() will fail with -EINVAL in case\nonline_pages_range() was never called (== no resource applicable in the\nrange).  Otherwise, we will always call online_pages_range() with nr_pages\n> 0 and, therefore, have online_pages > 0.\n\nRemove that special handling.\n\nLink: http://lkml.kernel.org/r/20190814154109.3448-6-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nCc: Arun KS <arunks@codeaurora.org>\nCc: Bjorn Helgaas <bhelgaas@google.com>\nCc: Borislav Petkov <bp@suse.de>\nCc: Dave Hansen <dave.hansen@linux.intel.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Nadav Amit <namit@vmware.com>\nCc: Wei Yang <richardw.yang@linux.intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:36:08.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug: make sure the pfn is aligned to the order when onl…",
                  "message": "mm/memory_hotplug: make sure the pfn is aligned to the order when onlining\n\nCommit a9cd410a3d29 (\"mm/page_alloc.c: memory hotplug: free pages as\nhigher order\") assumed that any PFN we get via memory resources is aligned\nto to MAX_ORDER - 1, I am not convinced that is always true.  Let's play\nsafe, check the alignment and fallback to single pages.\n\nakpm: warn in this situation so we get to find out if and why this ever\noccurs.\n\n[akpm@linux-foundation.org: add WARN_ON_ONCE()]\nLink: http://lkml.kernel.org/r/20190814154109.3448-5-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nCc: Arun KS <arunks@codeaurora.org>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nCc: Bjorn Helgaas <bhelgaas@google.com>\nCc: Borislav Petkov <bp@suse.de>\nCc: Dave Hansen <dave.hansen@linux.intel.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Nadav Amit <namit@vmware.com>\nCc: Wei Yang <richardw.yang@linux.intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:36:05.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug: simplify online_pages_range()",
                  "message": "mm/memory_hotplug: simplify online_pages_range()\n\nonline_pages always corresponds to nr_pages.  Simplify the code, getting\nrid of online_pages_blocks().  Add some comments.\n\nLink: http://lkml.kernel.org/r/20190814154109.3448-4-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nCc: Arun KS <arunks@codeaurora.org>\nCc: Bjorn Helgaas <bhelgaas@google.com>\nCc: Borislav Petkov <bp@suse.de>\nCc: Dave Hansen <dave.hansen@linux.intel.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Nadav Amit <namit@vmware.com>\nCc: Wei Yang <richardw.yang@linux.intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:36:02.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug: drop PageReserved() check in online_pages_range()",
                  "message": "mm/memory_hotplug: drop PageReserved() check in online_pages_range()\n\nmove_pfn_range_to_zone() will set all pages to PG_reserved via\nmemmap_init_zone().  The only way a page could no longer be reserved would\nbe if a MEM_GOING_ONLINE notifier would clear PG_reserved - which is not\ndone (the online_page callback is used for that purpose by e.g., Hyper-V\ninstead).  walk_system_ram_range() will never call online_pages_range()\nwith duplicate PFNs, so drop the PageReserved() check.\n\nThis seems to be a leftover from ancient times where the memmap was\ninitialized when adding memory and we wanted to check for already onlined\nmemory.\n\nLink: http://lkml.kernel.org/r/20190814154109.3448-3-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nCc: Arun KS <arunks@codeaurora.org>\nCc: Bjorn Helgaas <bhelgaas@google.com>\nCc: Borislav Petkov <bp@suse.de>\nCc: Dave Hansen <dave.hansen@linux.intel.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Nadav Amit <namit@vmware.com>\nCc: Wei Yang <richardw.yang@linux.intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:35:59.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug.c: use PFN_UP / PFN_DOWN in walk_system_ram_range()",
                  "message": "mm/memory_hotplug.c: use PFN_UP / PFN_DOWN in walk_system_ram_range()\n\nPatch series \"mm/memory_hotplug: online_pages() cleanups\", v2.\n\nSome cleanups (+ one fix for a special case) in the context of\nonline_pages().\n\nThis patch (of 5):\n\nThis makes it clearer that we will never call func() with duplicate PFNs\nin case we have multiple sub-page memory resources.  All unaligned parts\nof PFNs are completely discarded.\n\nLink: http://lkml.kernel.org/r/20190814154109.3448-2-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nReviewed-by: Wei Yang <richardw.yang@linux.intel.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nCc: Borislav Petkov <bp@suse.de>\nCc: Bjorn Helgaas <bhelgaas@google.com>\nCc: Ingo Molnar <mingo@kernel.org>\nCc: Dave Hansen <dave.hansen@linux.intel.com>\nCc: Nadav Amit <namit@vmware.com>\nCc: Oscar Salvador <osalvador@suse.de>\nCc: Arun KS <arunks@codeaurora.org>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:35:55.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug.c: prevent memory leak when reusing pgdat",
                  "message": "mm/memory_hotplug.c: prevent memory leak when reusing pgdat\n\nWhen offlining a node in try_offline_node(), pgdat is not released.  So\nthat pgdat could be reused in hotadd_new_pgdat().  While we reallocate\npgdat->per_cpu_nodestats if this pgdat is reused.\n\nThis patch prevents the memory leak by just allocating per_cpu_nodestats\nwhen it is a new pgdat.\n\nLink: http://lkml.kernel.org/r/20190813020608.10194-1-richardw.yang@linux.intel.com\nSigned-off-by: Wei Yang <richardw.yang@linux.intel.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: Oscar Salvador <OSalvador@suse.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Wei Yang",
                    "email": "richardw.yang@linux.intel.com",
                    "date": "2019-09-23T15:35:52.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "drivers/base/memory.c: don't store end_section_nr in memory blocks",
                  "message": "drivers/base/memory.c: don't store end_section_nr in memory blocks\n\nEach memory block spans the same amount of sections/pages/bytes.  The size\nis determined before the first memory block is created.  No need to store\nwhat we can easily calculate - and the calculations even look simpler now.\n\nMichal brought up the idea of variable-sized memory blocks.  However, if\nwe ever implement something like this, we will need an API compatibility\nswitch and reworks at various places (most code assumes a fixed memory\nblock size).  So let's cleanup what we have right now.\n\nWhile at it, fix the variable naming in register_mem_sect_under_node() -\nwe no longer talk about a single section.\n\nLink: http://lkml.kernel.org/r/20190809110200.2746-1-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nCc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nCc: \"Rafael J. Wysocki\" <rafael@kernel.org>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nCc: Oscar Salvador <osalvador@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:35:49.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "driver/base/memory.c: validate memory block size early",
                  "message": "driver/base/memory.c: validate memory block size early\n\nLet's validate the memory block size early, when initializing the memory\ndevice infrastructure.  Fail hard in case the value is not suitable.\n\nAs nobody checks the return value of memory_dev_init(), turn it into a\nvoid function and fail with a panic in all scenarios instead.  Otherwise,\nwe'll crash later during boot when core/drivers expect that the memory\ndevice infrastructure (including memory_block_size_bytes()) works as\nexpected.\n\nI think long term, we should move the whole memory block size\nconfiguration (set_memory_block_size_order() and\nmemory_block_size_bytes()) into drivers/base/memory.c.\n\nLink: http://lkml.kernel.org/r/20190806090142.22709-1-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nCc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nCc: \"Rafael J. Wysocki\" <rafael@kernel.org>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:35:46.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "drivers/base/memory.c: fixup documentation of removable/phys_index/bl…",
                  "message": "drivers/base/memory.c: fixup documentation of removable/phys_index/block_size_bytes\n\nLet's rephrase to memory block terminology and add some further\nclarifications.\n\nLink: http://lkml.kernel.org/r/20190806080826.5963-1-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nCc: \"Rafael J. Wysocki\" <rafael@kernel.org>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Oscar Salvador <osalvador@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:35:43.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "drivers/base/node.c: simplify unregister_memory_block_under_nodes()",
                  "message": "drivers/base/node.c: simplify unregister_memory_block_under_nodes()\n\nWe don't allow to offline memory block devices that belong to multiple\nnuma nodes.  Therefore, such devices can never get removed.  It is\nsufficient to process a single node when removing the memory block.  No\nneed to iterate over each and every PFN.\n\nWe already have the nid stored for each memory block.  Make sure that the\nnid always has a sane value.\n\nPlease note that checking for node_online(nid) is not required.  If we\nwould have a memory block belonging to a node that is no longer offline,\nthen we would have a BUG in the node offlining code.\n\nLink: http://lkml.kernel.org/r/20190719135244.15242-1-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nCc: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nCc: \"Rafael J. Wysocki\" <rafael@kernel.org>\nCc: David Hildenbrand <david@redhat.com>\nCc: Stephen Rothwell <sfr@canb.auug.org.au>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Michal Hocko <mhocko@suse.com>\nCc: Oscar Salvador <osalvador@suse.de>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:35:40.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/memory_hotplug: remove move_pfn_range()",
                  "message": "mm/memory_hotplug: remove move_pfn_range()\n\nLet's remove this indirection.  We need the zone in the caller either way,\nso let's just detect it there.  Add some documentation for\nmove_pfn_range_to_zone() instead.\n\n[akpm@linux-foundation.org: restore newline, per David]\nLink: http://lkml.kernel.org/r/20190724142324.3686-1-david@redhat.com\nSigned-off-by: David Hildenbrand <david@redhat.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nReviewed-by: Oscar Salvador <osalvador@suse.de>\nCc: David Hildenbrand <david@redhat.com>\nCc: Pavel Tatashin <pasha.tatashin@soleen.com>\nCc: Dan Williams <dan.j.williams@intel.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE1NDcyMDU=",
                      "login": "davidhildenbrand"
                    },
                    "name": "David Hildenbrand",
                    "email": "david@redhat.com",
                    "date": "2019-09-23T15:35:37.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: do not hash address in print_bad_pte()",
                  "message": "mm: do not hash address in print_bad_pte()\n\nUsing %px to show the actual address in print_bad_pte()\nto help us to debug issue.\n\nLink: http://lkml.kernel.org/r/20190831011816.141002-1-wangkefeng.wang@huawei.com\nSigned-off-by: Kefeng Wang <wangkefeng.wang@huawei.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Kefeng Wang",
                    "email": "wangkefeng.wang@huawei.com",
                    "date": "2019-09-23T15:35:34.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: consolidate pgtable_cache_init() and pgd_cache_init()",
                  "message": "mm: consolidate pgtable_cache_init() and pgd_cache_init()\n\nBoth pgtable_cache_init() and pgd_cache_init() are used to initialize kmem\ncache for page table allocations on several architectures that do not use\nPAGE_SIZE tables for one or more levels of the page table hierarchy.\n\nMost architectures do not implement these functions and use __weak default\nNOP implementation of pgd_cache_init().  Since there is no such default\nfor pgtable_cache_init(), its empty stub is duplicated among most\narchitectures.\n\nRename the definitions of pgd_cache_init() to pgtable_cache_init() and\ndrop empty stubs of pgtable_cache_init().\n\nLink: http://lkml.kernel.org/r/1566457046-22637-1-git-send-email-rppt@linux.ibm.com\nSigned-off-by: Mike Rapoport <rppt@linux.ibm.com>\nAcked-by: Will Deacon <will@kernel.org>\t\t[arm64]\nAcked-by: Thomas Gleixner <tglx@linutronix.de>\t[x86]\nCc: Catalin Marinas <catalin.marinas@arm.com>\nCc: Ingo Molnar <mingo@redhat.com>\nCc: Borislav Petkov <bp@alien8.de>\nCc: Matthew Wilcox <willy@infradead.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Mike Rapoport",
                    "email": "rppt@linux.ibm.com",
                    "date": "2019-09-23T15:35:31.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "microblaze: switch to generic version of pte allocation",
                  "message": "microblaze: switch to generic version of pte allocation\n\nThe microblaze implementation of pte_alloc_one() has a provision to\nallocated PTEs from high memory, but neither CONFIG_HIGHPTE nor pte_map*()\nversions for suitable for HIGHPTE are defined.\n\nExcept that, microblaze version of pte_alloc_one() is identical to the\ngeneric one as well as the implementations of pte_free() and\npte_free_kernel().\n\nSwitch microblaze to use the generic versions of these functions.  Also\nremove pte_free_slow() that is not referenced anywhere in the code.\n\nLink: http://lkml.kernel.org/r/1565690952-32158-1-git-send-email-rppt@linux.ibm.com\nSigned-off-by: Mike Rapoport <rppt@linux.ibm.com>\nAcked-by: Mark Rutland <mark.rutland@arm.com>\nCc: Michal Simek <monstr@monstr.eu>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Mike Rapoport",
                    "email": "rppt@linux.ibm.com",
                    "date": "2019-09-23T15:35:28.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "sh: switch to generic version of pte allocation",
                  "message": "sh: switch to generic version of pte allocation\n\nThe sh implementation pte_alloc_one(), pte_alloc_one_kernel(),\npte_free_kernel() and pte_free() is identical to the generic except of\nlack of __GFP_ACCOUNT for the user PTEs allocation.\n\nSwitch sh to use generic version of these functions.\n\nLink: http://lkml.kernel.org/r/1565250728-21721-4-git-send-email-rppt@linux.ibm.com\nSigned-off-by: Mike Rapoport <rppt@linux.ibm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Mike Rapoport",
                    "email": "rppt@linux.ibm.com",
                    "date": "2019-09-23T15:35:25.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "ia64: switch to generic version of pte allocation",
                  "message": "ia64: switch to generic version of pte allocation\n\nThe ia64 implementation pte_alloc_one(), pte_alloc_one_kernel(),\npte_free_kernel() and pte_free() is identical to the generic except of\nlack of __GFP_ACCOUNT for the user PTEs allocation.\n\nSwitch ia64 to use generic version of these functions.\n\nLink: http://lkml.kernel.org/r/1565250728-21721-3-git-send-email-rppt@linux.ibm.com\nSigned-off-by: Mike Rapoport <rppt@linux.ibm.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Mike Rapoport",
                    "email": "rppt@linux.ibm.com",
                    "date": "2019-09-23T15:35:22.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: remove quicklist page table caches",
                  "message": "mm: remove quicklist page table caches\n\nPatch series \"mm: remove quicklist page table caches\".\n\nA while ago Nicholas proposed to remove quicklist page table caches [1].\n\nI've rebased his patch on the curren upstream and switched ia64 and sh to\nuse generic versions of PTE allocation.\n\n[1] https://lore.kernel.org/linux-mm/20190711030339.20892-1-npiggin@gmail.com\n\nThis patch (of 3):\n\nRemove page table allocator \"quicklists\".  These have been around for a\nlong time, but have not got much traction in the last decade and are only\nused on ia64 and sh architectures.\n\nThe numbers in the initial commit look interesting but probably don't\napply anymore.  If anybody wants to resurrect this it's in the git\nhistory, but it's unhelpful to have this code and divergent allocator\nbehaviour for minor archs.\n\nAlso it might be better to instead make more general improvements to page\nallocator if this is still so slow.\n\nLink: http://lkml.kernel.org/r/1565250728-21721-2-git-send-email-rppt@linux.ibm.com\nSigned-off-by: Nicholas Piggin <npiggin@gmail.com>\nSigned-off-by: Mike Rapoport <rppt@linux.ibm.com>\nCc: Tony Luck <tony.luck@intel.com>\nCc: Yoshinori Sato <ysato@users.sourceforge.jp>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjE5ODMzMDAy",
                      "login": "npiggin"
                    },
                    "name": "Nicholas Piggin",
                    "email": "npiggin@gmail.com",
                    "date": "2019-09-23T15:35:19.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: release the spinlock on zap_pte_range",
                  "message": "mm: release the spinlock on zap_pte_range\n\nIn our testing (camera recording), Miguel and Wei found\nunmap_page_range() takes above 6ms with preemption disabled easily.\nWhen I see that, the reason is it holds page table spinlock during\nentire 512 page operation in a PMD.  6.2ms is never trivial for user\nexperince if RT task couldn't run in the time because it could make\nframe drop or glitch audio problem.\n\nI had a time to benchmark it via adding some trace_printk hooks between\npte_offset_map_lock and pte_unmap_unlock in zap_pte_range.  The testing\ndevice is 2018 premium mobile device.\n\nI can get 2ms delay rather easily to release 2M(ie, 512 pages) when the\ntask runs on little core even though it doesn't have any IPI and LRU\nlock contention.  It's already too heavy.\n\nIf I remove activate_page, 35-40% overhead of zap_pte_range is gone so\nmost of overhead(about 0.7ms) comes from activate_page via\nmark_page_accessed.  Thus, if there are LRU contention, that 0.7ms could\naccumulate up to several ms.\n\nSo this patch adds a check for need_resched() in the loop, and a\npreemption point if necessary.\n\nLink: http://lkml.kernel.org/r/20190731061440.GC155569@google.com\nSigned-off-by: Minchan Kim <minchan@kernel.org>\nReported-by: Miguel de Dios <migueldedios@google.com>\nReported-by: Wei Wang <wvw@google.com>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Michal Hocko <mhocko@kernel.org>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Mel Gorman <mgorman@techsingularity.net>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjYwOTA1NzA=",
                      "login": "minchank"
                    },
                    "name": "Minchan Kim",
                    "email": "minchan@kernel.org",
                    "date": "2019-09-24T00:02:24.000Z"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: remove redundant assignment of entry",
                  "message": "mm: remove redundant assignment of entry\n\nSince ptent will not be changed after previous assignment of entry, it is\nnot necessary to do the assignment again.\n\nLink: http://lkml.kernel.org/r/20190708082740.21111-1-richardw.yang@linux.intel.com\nSigned-off-by: Wei Yang <richardw.yang@linux.intel.com>\nAcked-by: Matthew Wilcox (Oracle) <willy@infradead.org>\nCc: Will Deacon <will@kernel.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Wei Yang",
                    "email": "richardw.yang@linux.intel.com",
                    "date": "2019-09-23T15:35:13.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "net/xdp: convert put_page() to put_user_page*()",
                  "message": "net/xdp: convert put_page() to put_user_page*()\n\nFor pages that were retained via get_user_pages*(), release those pages\nvia the new put_user_page*() routines, instead of via put_page() or\nrelease_pages().\n\nThis is part a tree-wide conversion, as described in fc1d8e7cca2d (\"mm:\nintroduce put_user_page*(), placeholder versions\").\n\nLink: http://lkml.kernel.org/r/20190724044537.10458-4-jhubbard@nvidia.com\nSigned-off-by: John Hubbard <jhubbard@nvidia.com>\nAcked-by: Björn Töpel <bjorn.topel@intel.com>\nCc: Björn Töpel <bjorn.topel@intel.com>\nCc: Magnus Karlsson <magnus.karlsson@intel.com>\nCc: David S. Miller <davem@davemloft.net>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjIxNzA5NzE=",
                      "login": "johnhubbard"
                    },
                    "name": "John Hubbard",
                    "email": "jhubbard@nvidia.com",
                    "date": "2019-09-23T15:35:10.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "drivers/gpu/drm/via: convert put_page() to put_user_page*()",
                  "message": "drivers/gpu/drm/via: convert put_page() to put_user_page*()\n\nFor pages that were retained via get_user_pages*(), release those pages\nvia the new put_user_page*() routines, instead of via put_page() or\nrelease_pages().\n\nThis is part a tree-wide conversion, as described in fc1d8e7cca2d (\"mm:\nintroduce put_user_page*(), placeholder versions\").\n\nAlso reverse the order of a comparison, in order to placate checkpatch.pl.\n\nLink: http://lkml.kernel.org/r/20190724044537.10458-3-jhubbard@nvidia.com\nSigned-off-by: John Hubbard <jhubbard@nvidia.com>\nCc: David Airlie <airlied@linux.ie>\nCc: Daniel Vetter <daniel@ffwll.ch>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjIxNzA5NzE=",
                      "login": "johnhubbard"
                    },
                    "name": "John Hubbard",
                    "email": "jhubbard@nvidia.com",
                    "date": "2019-09-23T15:35:07.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/gup: add make_dirty arg to put_user_pages_dirty_lock()",
                  "message": "mm/gup: add make_dirty arg to put_user_pages_dirty_lock()\n\n[11~From: John Hubbard <jhubbard@nvidia.com>\nSubject: mm/gup: add make_dirty arg to put_user_pages_dirty_lock()\n\nPatch series \"mm/gup: add make_dirty arg to put_user_pages_dirty_lock()\",\nv3.\n\nThere are about 50+ patches in my tree [2], and I'll be sending out the\nremaining ones in a few more groups:\n\n* The block/bio related changes (Jerome mostly wrote those, but I've had\n  to move stuff around extensively, and add a little code)\n\n* mm/ changes\n\n* other subsystem patches\n\n* an RFC that shows the current state of the tracking patch set.  That\n  can only be applied after all call sites are converted, but it's good to\n  get an early look at it.\n\nThis is part a tree-wide conversion, as described in fc1d8e7cca2d (\"mm:\nintroduce put_user_page*(), placeholder versions\").\n\nThis patch (of 3):\n\nProvide more capable variation of put_user_pages_dirty_lock(), and delete\nput_user_pages_dirty().  This is based on the following:\n\n1.  Lots of call sites become simpler if a bool is passed into\n   put_user_page*(), instead of making the call site choose which\n   put_user_page*() variant to call.\n\n2.  Christoph Hellwig's observation that set_page_dirty_lock() is\n   usually correct, and set_page_dirty() is usually a bug, or at least\n   questionable, within a put_user_page*() calling chain.\n\nThis leads to the following API choices:\n\n    * put_user_pages_dirty_lock(page, npages, make_dirty)\n\n    * There is no put_user_pages_dirty(). You have to\n      hand code that, in the rare case that it's\n      required.\n\n[jhubbard@nvidia.com: remove unused variable in siw_free_plist()]\n  Link: http://lkml.kernel.org/r/20190729074306.10368-1-jhubbard@nvidia.com\nLink: http://lkml.kernel.org/r/20190724044537.10458-2-jhubbard@nvidia.com\nSigned-off-by: John Hubbard <jhubbard@nvidia.com>\nCc: Matthew Wilcox <willy@infradead.org>\nCc: Jan Kara <jack@suse.cz>\nCc: Christoph Hellwig <hch@lst.de>\nCc: Ira Weiny <ira.weiny@intel.com>\nCc: Jason Gunthorpe <jgg@ziepe.ca>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjMxNTIzNDQ2",
                      "login": "akpm00"
                    },
                    "name": "akpm@linux-foundation.org",
                    "email": "akpm@linux-foundation.org",
                    "date": "2019-09-23T15:35:04.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: vmscan: do not share cgroup iteration between reclaimers",
                  "message": "mm: vmscan: do not share cgroup iteration between reclaimers\n\nOne of our services observed a high rate of cgroup OOM kills in the\npresence of large amounts of clean cache.  Debugging showed that the\nculprit is the shared cgroup iteration in page reclaim.\n\nUnder high allocation concurrency, multiple threads enter reclaim at the\nsame time.  Fearing overreclaim when we first switched from the single\nglobal LRU to cgrouped LRU lists, we introduced a shared iteration state\nfor reclaim invocations - whether 1 or 20 reclaimers are active\nconcurrently, we only walk the cgroup tree once: the 1st reclaimer\nreclaims the first cgroup, the second the second one etc.  With more\nreclaimers than cgroups, we start another walk from the top.\n\nThis sounded reasonable at the time, but the problem is that reclaim\nconcurrency doesn't scale with allocation concurrency.  As reclaim\nconcurrency increases, the amount of memory individual reclaimers get to\nscan gets smaller and smaller.  Individual reclaimers may only see one\ncgroup per cycle, and that may not have much reclaimable memory.  We see\nindividual reclaimers declare OOM when there is plenty of reclaimable\nmemory available in cgroups they didn't visit.\n\nThis patch does away with the shared iterator, and every reclaimer is\nallowed to scan the full cgroup tree and see all of reclaimable memory,\njust like it would on a non-cgrouped system.  This way, when OOM is\ndeclared, we know that the reclaimer actually had a chance.\n\nTo still maintain fairness in reclaim pressure, disallow cgroup reclaim\nfrom bailing out of the tree walk early.  Kswapd and regular direct\nreclaim already don't bail, so it's not clear why limit reclaim would have\nto, especially since it only walks subtrees to begin with.\n\nThis change completely eliminates the OOM kills on our service, while\nshowing no signs of overreclaim - no increased scan rates, %sys time, or\nabrupt free memory spikes.  I tested across 100 machines that have 64G of\nRAM and host about 300 cgroups each.\n\n[ It's possible overreclaim never was a *practical* issue to begin\n  with - it was simply a concern we had on the mailing lists at the\n  time, with no real data to back it up. But we have also added more\n  bail-out conditions deeper inside reclaim (e.g. the proportional\n  exit in shrink_node_memcg) since. Regardless, now we have data that\n  suggests full walks are more reliable and scale just fine. ]\n\nLink: http://lkml.kernel.org/r/20190812192316.13615-1-hannes@cmpxchg.org\nSigned-off-by: Johannes Weiner <hannes@cmpxchg.org>\nReviewed-by: Roman Gushchin <guro@fb.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjEyNzI4MTY=",
                      "login": "hnaz"
                    },
                    "name": "Johannes Weiner",
                    "email": "hannes@cmpxchg.org",
                    "date": "2019-09-23T15:35:01.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: memcontrol: switch to rcu protection in drain_all_stock()",
                  "message": "mm: memcontrol: switch to rcu protection in drain_all_stock()\n\nCommit 72f0184c8a00 (\"mm, memcg: remove hotplug locking from try_charge\")\nintroduced css_tryget()/css_put() calls in drain_all_stock(), which are\nsupposed to protect the target memory cgroup from being released during\nthe mem_cgroup_is_descendant() call.\n\nHowever, it's not completely safe.  In theory, memcg can go away between\nreading stock->cached pointer and calling css_tryget().\n\nThis can happen if drain_all_stock() races with drain_local_stock()\nperformed on the remote cpu as a result of a work, scheduled by the\nprevious invocation of drain_all_stock().\n\nThe race is a bit theoretical and there are few chances to trigger it, but\nthe current code looks a bit confusing, so it makes sense to fix it\nanyway.  The code looks like as if css_tryget() and css_put() are used to\nprotect stocks drainage.  It's not necessary because stocked pages are\nholding references to the cached cgroup.  And it obviously won't work for\nworks, scheduled on other cpus.\n\nSo, let's read the stock->cached pointer and evaluate the memory cgroup\ninside a rcu read section, and get rid of css_tryget()/css_put() calls.\n\nLink: http://lkml.kernel.org/r/20190802192241.3253165-1-guro@fb.com\nSigned-off-by: Roman Gushchin <guro@fb.com>\nAcked-by: Michal Hocko <mhocko@suse.com>\nCc: Hillf Danton <hdanton@sina.com>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Vladimir Davydov <vdavydov.dev@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjg1MjIxMjk=",
                      "login": "rgushchin"
                    },
                    "name": "Roman Gushchin",
                    "email": "guro@fb.com",
                    "date": "2019-09-23T15:34:58.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm, memcg: throttle allocators when failing reclaim over memory.high",
                  "message": "mm, memcg: throttle allocators when failing reclaim over memory.high\n\nWe're trying to use memory.high to limit workloads, but have found that\ncontainment can frequently fail completely and cause OOM situations\noutside of the cgroup.  This happens especially with swap space -- either\nwhen none is configured, or swap is full.  These failures often also don't\nhave enough warning to allow one to react, whether for a human or for a\ndaemon monitoring PSI.\n\nHere is output from a simple program showing how long it takes in usec\n(column 2) to allocate a megabyte of anonymous memory (column 1) when a\ncgroup is already beyond its memory high setting, and no swap is\navailable:\n\n    [root@ktst ~]# systemd-run -p MemoryHigh=100M -p MemorySwapMax=1 \\\n    > --wait -t timeout 300 /root/mdf\n    [...]\n    95  1035\n    96  1038\n    97  1000\n    98  1036\n    99  1048\n    100 1590\n    101 1968\n    102 1776\n    103 1863\n    104 1757\n    105 1921\n    106 1893\n    107 1760\n    108 1748\n    109 1843\n    110 1716\n    111 1924\n    112 1776\n    113 1831\n    114 1766\n    115 1836\n    116 1588\n    117 1912\n    118 1802\n    119 1857\n    120 1731\n    [...]\n    [System OOM in 2-3 seconds]\n\nThe delay does go up extremely marginally past the 100MB memory.high\nthreshold, as now we spend time scanning before returning to usermode, but\nit's nowhere near enough to contain growth.  It also doesn't get worse the\nmore pages you have, since it only considers nr_pages.\n\nThe current situation goes against both the expectations of users of\nmemory.high, and our intentions as cgroup v2 developers.  In\ncgroup-v2.txt, we claim that we will throttle and only under \"extreme\nconditions\" will memory.high protection be breached.  Likewise, cgroup v2\nusers generally also expect that memory.high should throttle workloads as\nthey exceed their high threshold.  However, as seen above, this isn't\nalways how it works in practice -- even on banal setups like those with no\nswap, or where swap has become exhausted, we can end up with memory.high\nbeing breached and us having no weapons left in our arsenal to combat\nrunaway growth with, since reclaim is futile.\n\nIt's also hard for system monitoring software or users to tell how bad the\nsituation is, as \"high\" events for the memcg may in some cases be benign,\nand in others be catastrophic.  The current status quo is that we fail\ncontainment in a way that doesn't provide any advance warning that things\nare about to go horribly wrong (for example, we are about to invoke the\nkernel OOM killer).\n\nThis patch introduces explicit throttling when reclaim is failing to keep\nmemcg size contained at the memory.high setting.  It does so by applying\nan exponential delay curve derived from the memcg's overage compared to\nmemory.high.  In the normal case where the memcg is either below or only\nmarginally over its memory.high setting, no throttling will be performed.\n\nThis composes well with system health monitoring and remediation, as these\nallocator delays are factored into PSI's memory pressure calculations.\nThis both creates a mechanism system administrators or applications\nconsuming the PSI interface to trivially see that the memcg in question is\nstruggling and use that to make more reasonable decisions, and permits\nthem enough time to act.  Either of these can act with significantly more\nnuance than that we can provide using the system OOM killer.\n\nThis is a similar idea to memory.oom_control in cgroup v1 which would put\nthe cgroup to sleep if the threshold was violated, but it's also\nsignificantly improved as it results in visible memory pressure, and also\ndoesn't schedule indefinitely, which previously made tracing and other\nintrospection difficult (ie.  it's clamped at 2*HZ per allocation through\nMEMCG_MAX_HIGH_DELAY_JIFFIES).\n\nContrast the previous results with a kernel with this patch:\n\n    [root@ktst ~]# systemd-run -p MemoryHigh=100M -p MemorySwapMax=1 \\\n    > --wait -t timeout 300 /root/mdf\n    [...]\n    95  1002\n    96  1000\n    97  1002\n    98  1003\n    99  1000\n    100 1043\n    101 84724\n    102 330628\n    103 610511\n    104 1016265\n    105 1503969\n    106 2391692\n    107 2872061\n    108 3248003\n    109 4791904\n    110 5759832\n    111 6912509\n    112 8127818\n    113 9472203\n    114 12287622\n    115 12480079\n    116 14144008\n    117 15808029\n    118 16384500\n    119 16383242\n    120 16384979\n    [...]\n\nAs you can see, in the normal case, memory allocation takes around 1000\nusec.  However, as we exceed our memory.high, things start to increase\nexponentially, but fairly leniently at first.  Our first megabyte over\nmemory.high takes us 0.16 seconds, then the next is 0.46 seconds, then the\nnext is almost an entire second.  This gets worse until we reach our\neventual 2*HZ clamp per batch, resulting in 16 seconds per megabyte.\nHowever, this is still making forward progress, so permits tracing or\nfurther analysis with programs like GDB.\n\nWe use an exponential curve for our delay penalty for a few reasons:\n\n1. We run mem_cgroup_handle_over_high to potentially do reclaim after\n   we've already performed allocations, which means that temporarily\n   going over memory.high by a small amount may be perfectly legitimate,\n   even for compliant workloads. We don't want to unduly penalise such\n   cases.\n2. An exponential curve (as opposed to a static or linear delay) allows\n   ramping up memory pressure stats more gradually, which can be useful\n   to work out that you have set memory.high too low, without destroying\n   application performance entirely.\n\nThis patch expands on earlier work by Johannes Weiner. Thanks!\n\n[akpm@linux-foundation.org: fix max() warning]\n[akpm@linux-foundation.org: fix __udivdi3 ref on 32-bit]\n[akpm@linux-foundation.org: fix it even more]\n[chris@chrisdown.name: fix 64-bit divide even more]\nLink: http://lkml.kernel.org/r/20190723180700.GA29459@chrisdown.name\nSigned-off-by: Chris Down <chris@chrisdown.name>\nAcked-by: Johannes Weiner <hannes@cmpxchg.org>\nCc: Tejun Heo <tj@kernel.org>\nCc: Roman Gushchin <guro@fb.com>\nCc: Michal Hocko <mhocko@kernel.org>\nCc: Nathan Chancellor <natechancellor@gmail.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjY2MDY2Mw==",
                      "login": "cdown"
                    },
                    "name": "Chris Down",
                    "email": "chris@chrisdown.name",
                    "date": "2019-09-23T15:34:55.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm: page cache: store only head pages in i_pages",
                  "message": "mm: page cache: store only head pages in i_pages\n\nTransparent Huge Pages are currently stored in i_pages as pointers to\nconsecutive subpages.  This patch changes that to storing consecutive\npointers to the head page in preparation for storing huge pages more\nefficiently in i_pages.\n\nLarge parts of this are \"inspired\" by Kirill's patch\nhttps://lore.kernel.org/lkml/20170126115819.58875-2-kirill.shutemov@linux.intel.com/\n\nKirill and Huang Ying contributed several fixes.\n\n[willy@infradead.org: use compound_nr, squish uninit-var warning]\nLink: http://lkml.kernel.org/r/20190731210400.7419-1-willy@infradead.org\nSigned-off-by: Matthew Wilcox <willy@infradead.org>\nAcked-by: Jan Kara <jack@suse.cz>\nReviewed-by: Kirill Shutemov <kirill@shutemov.name>\nReviewed-by: Song Liu <songliubraving@fb.com>\nTested-by: Song Liu <songliubraving@fb.com>\nTested-by: William Kucharski <william.kucharski@oracle.com>\nReviewed-by: William Kucharski <william.kucharski@oracle.com>\nTested-by: Qian Cai <cai@lca.pw>\nTested-by: Mikhail Gavrilov <mikhail.v.gavrilov@gmail.com>\nCc: Hugh Dickins <hughd@google.com>\nCc: Chris Wilson <chris@chris-wilson.co.uk>\nCc: Song Liu <songliubraving@fb.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": null,
                    "name": "Matthew Wilcox (Oracle)",
                    "email": "willy@infradead.org",
                    "date": "2019-09-23T15:34:52.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/filemap.c: rewrite mapping_needs_writeback in less fancy manner",
                  "message": "mm/filemap.c: rewrite mapping_needs_writeback in less fancy manner\n\nThis actually checks that writeback is needed or in progress.\n\nLink: http://lkml.kernel.org/r/156378817069.1087.1302816672037672488.stgit@buzz\nSigned-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>\nReviewed-by: Andrew Morton <akpm@linux-foundation.org>\nCc: Tejun Heo <tj@kernel.org>\nCc: Jens Axboe <axboe@kernel.dk>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nCc: Jan Kara <jack@suse.cz>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjQyNjUwNg==",
                      "login": "koct9i"
                    },
                    "name": "Konstantin Khlebnikov",
                    "email": "khlebnikov@yandex-team.ru",
                    "date": "2019-09-23T15:34:48.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              },
              {
                "node": {
                  "messageHeadline": "mm/filemap.c: don't initiate writeback if mapping has no dirty pages",
                  "message": "mm/filemap.c: don't initiate writeback if mapping has no dirty pages\n\nFunctions like filemap_write_and_wait_range() should do nothing if inode\nhas no dirty pages or pages currently under writeback.  But they anyway\nconstruct struct writeback_control and this does some atomic operations if\nCONFIG_CGROUP_WRITEBACK=y - on fast path it locks inode->i_lock and\nupdates state of writeback ownership, on slow path might be more work.\nCurrent this path is safely avoided only when inode mapping has no pages.\n\nFor example generic_file_read_iter() calls filemap_write_and_wait_range()\nat each O_DIRECT read - pretty hot path.\n\nThis patch skips starting new writeback if mapping has no dirty tags set.\nIf writeback is already in progress filemap_write_and_wait_range() will\nwait for it.\n\nLink: http://lkml.kernel.org/r/156378816804.1087.8607636317907921438.stgit@buzz\nSigned-off-by: Konstantin Khlebnikov <khlebnikov@yandex-team.ru>\nReviewed-by: Jan Kara <jack@suse.cz>\nCc: Tejun Heo <tj@kernel.org>\nCc: Jens Axboe <axboe@kernel.dk>\nCc: Johannes Weiner <hannes@cmpxchg.org>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
                  "author": {
                    "user": {
                      "id": "MDQ6VXNlcjQyNjUwNg==",
                      "login": "koct9i"
                    },
                    "name": "Konstantin Khlebnikov",
                    "email": "khlebnikov@yandex-team.ru",
                    "date": "2019-09-23T15:34:45.000-07:00"
                  },
                  "comments": {
                    "edges": []
                  }
                }
              }
            ]
          }
        }
      }
    }
  }
}