{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "# TODO:\n",
        "# Make nodes bigger/another colour\n",
        "\n",
        "# ----------------------------------------------------------------------------\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# COSC2671 Social Media and Network Analytics\n",
        "## Assignment 2\n",
        "### @author Phil Steinke, student: s3725547 github: tgrrr\n",
        "### @author Oli FIXME, student: FIXME github: shaggycamel\n",
        "### @author FIXME Aidan Cowie, student: s3429481 github: aidancowie\n",
        "### Due FIXME\n",
        "\n",
        "----------------------------------------------------------------------------\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Introduction\n",
        "## Describe what/who is your selected entity\n",
        "## Describe why it is interesting to find the sentiment and topics (answer questions) of this entity\n",
        "\n",
        "#### RUBRIC: Problem Formulation (15%)\n",
        "- [ ] The proposed problem/question is interesting, well-motivated and non-trivial. \n",
        "- [ ] Problem and success criteria are well designed and thought out, \n",
        "  - [ ] and scope is realistic.\n",
        "\n",
        "## Problem or Question Construction\n",
        "\n",
        "- [ ] Must include at least one source of social media and networks.\n",
        "- [ ] Must include a graph or network and its analysis/processing to solve a problem.\n",
        "- [ ] Must include some element of analysis using social media and networks, and something we learnt in class. It cannot be all machine learning for example.\n",
        "- [ ] Your analyst or solution is in Python (no R, including visualisation), but parts of it could be done in other languages, e.g., Javascript if you decide to prototype a front end on website.\n",
        "- [ ] All code should be your own, you can leverage packages such as `networkx` etc., but it shouldnâ€™t be copied from an existing solution.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Data Collection\n",
        "## Describe how you collected the data, and briefly why you chose that approach (restful vs stream)\n",
        "## Report some statistics of your collected data\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "PATH = '/Users/phil/code/data-science-next/uni/social-media/ass02_datascience_social_network_analysis/packages/server'\n",
        "os.chdir(PATH)\n",
        "\n",
        "from src.data import * # fetch_github_query, Auth.HEADERS\n",
        "from src.data.auth import * # fetch_github_query, Auth.HEADERS\n",
        "from src.config import * # Constants, including URL, PATH\n",
        "from src.data.queries import queries\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What it includes:\n",
        "\n",
        "- github api v4 \n",
        "- graphql queries\n",
        "- python 3.7\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "result_charity = do_fetch_github_query(queries.query_repo, queries.variables_repo)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "How many repos:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "repos_charity_count = result_charity['search']['repositoryCount']\n",
        "print(repos_charity_count)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What are the top repos?\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "repos_charity = result_charity['search']['edges']\n",
        "\n",
        "# import json\n",
        "for i in repos_charity:\n",
        "    _name = i['node']['name']\n",
        "    _url = i['node']['url']\n",
        "    _stars = str(i['node']['stargazers']['totalCount'])\n",
        "    print(\"Name: %(n)s \\nstars: %(s)s \\nurl: %(u)s\\n\" \n",
        "        % {'n': _name, 'u': _url, 's': _stars})\n",
        "    # print(json.dumps(i))\n",
        "\n",
        "# get values from repo results for #1\n",
        "# for key, value in repos_charity[1]['node'].items():\n",
        "#     print(key, value)\n",
        "\n",
        "# more concise code:\n",
        "# repo_arr = [i['node']['name'] for i in repos_charity]\n",
        "# repo_arr\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# TODO: Pre-processing and Data Cleaning\n",
        "## TODO: Describe  what pre-processing you performed\n",
        "## TODO: Show examples of noisy data, plot some graphs, etc to show why you decided to do those pre-processing\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to obj to make data easier to access:\n",
        "# FIXME:\n",
        "from collections import namedtuple\n",
        "def _json_object_hook(d): return namedtuple('X', d.keys())(*d.values())\n",
        "def json2obj(data): return json.loads(data, object_hook=_json_object_hook)\n",
        "result_charity_obj = json2obj(json.dumps(result_charity))\n",
        "# dir(result_charity_obj.search.edges[1])\n",
        "\n",
        "# before:\n",
        "result_charity['search']['repositoryCount']\n",
        "#after:\n",
        "result_charity_obj.search.repositoryCount\n",
        "\n",
        "result_charity_obj.search.edges[1].node.stargazers.totalCount\n",
        "\n",
        "# Have we gone over the query count?\n",
        "\n",
        "result_rate_limit = fetch_github_query(queries.query_rate_limit) # Execute the query\n",
        "remaining_rate_limit = result_rate_limit[\"rateLimit\"][\"remaining\"] # Drill down the dictionary\n",
        "print(\"Remaining rate limit - {}\".format(remaining_rate_limit))\n",
        "\n",
        "# WIP: Query about charities\n",
        "# see: https://developer.github.com/v4/explorer/\n",
        "# queries: https://developer.github.com/v4/query/\n",
        "# FIXME: KeyError: data\n",
        "result_nonprofit = fetch_github_query(queries.query_nonprofit)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Goal:**  Show a network of developers that are contributing to open source projects\n",
        "\n",
        "- ggplot2\n",
        "- spark\n",
        "- tidyverse\n",
        "- linux\n",
        "- django\n",
        "- keras\n",
        "- pandas\n",
        "- ipython\n",
        "- scikit-learn\n",
        "- node\n",
        "- tensorflow\n",
        "- TODO: FreeCodeCamp https://github.com/freeCodeCamp/freeCodeCamp\n",
        "- TODO: Linux\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from os import listdir\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import pandas as pd\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Get list of json files in directory\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/Users/phil/code/data-science-next/uni/social-media/ass02_datascience_social_network_analysis/packages/server/data/raw'\n",
        "FIGURES_PATH = '/Users/phil/code/data-science-next/uni/social-media/ass02_datascience_social_network_analysis/packages/server/notebooks/figures/'\n",
        "\n",
        "os.chdir(PATH)\n",
        "\n",
        "# Set default figure size for plots:\n",
        "matplotlib.rc('figure', figsize=(10, 10))\n",
        "\n",
        "# From Oli's Jupyter notebook:\n",
        "files_in_drive = listdir(PATH)\n",
        "json_files = []\n",
        "for ix, file in enumerate(files_in_drive):\n",
        "    if('.json' in file):\n",
        "        json_files.append(file)\n",
        "   \n",
        "# Remove files if wanted\n",
        "rm = []\n",
        "# rm.append(['linux', 'ipython', 'spark', 'node']) # cosc\n",
        "# rm.append(['django', 'keras', 'tensorflow', 'pandas', 'scikit-learn']) # Python\n",
        "# rm.append(['ggplot2', 'tidyverse']) # R\n",
        "for layer in rm:\n",
        "    for f in layer:\n",
        "        json_files.remove(f+\".json\")\n",
        "json_files\n",
        "\n",
        "# Prepare keys for dictionary\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = []\n",
        "for file in json_files:\n",
        "    start = file.find('.')\n",
        "    file_names.append(file[0:start])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Put all json data into dictionary\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "data = {}\n",
        "for ix, file in enumerate(json_files):\n",
        "    tmp = json.loads(open(file, encoding=\"utf-8\").read())\n",
        "    data[file_names[ix]] = tmp['data']['repository']['ref']['target']['history']['edges']\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph with weight\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "repo_weight = []\n",
        "user_list = []\n",
        "repo_user_list = {}\n",
        "network_weight = nx.Graph()\n",
        "\n",
        "for repo in data:\n",
        "    ix = 0\n",
        "    network_weight.add_node(repo)\n",
        "    while ix < len(data[repo]):\n",
        "        try:\n",
        "            user = data[repo][ix]['node']['author']['user']['login']\n",
        "            network_weight.add_node(user)\n",
        "            repo_weight.append(repo + \" \" + user)\n",
        "            user_list.append(user)\n",
        "        except:\n",
        "            pass\n",
        "        ix += 1\n",
        "    repo_user_list[repo] = list(set(user_list))\n",
        "\n",
        "repo_weight = Counter(repo_weight)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for weight in repo_weight:\n",
        "    space = weight.find(' ')\n",
        "    r = weight[0:space].strip()\n",
        "    u = weight[space+1:len(weight)].strip()\n",
        "    w = repo_weight[weight]\n",
        "    network_weight.add_edge(r, u, weight=w)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(network_weight, with_labels=True, pos=nx.kamada_kawai_layout(network_weight, scale=10))\n",
        "plt.axis('off')\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10) # new\n",
        "plt.savefig(FIGURES_PATH + 'network_with_weight.png', bbox_inches='tight') # new\n",
        "\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph without weight\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "network_no_weight = nx.Graph()\n",
        "\n",
        "for repo in data:\n",
        "    network_no_weight.add_node(repo)\n",
        "    ix = 0\n",
        "    while ix < len(data[repo]):\n",
        "        try:\n",
        "            user = data[repo][ix]['node']['author']['user']['login']\n",
        "            network_no_weight.add_node(user)\n",
        "            network_no_weight.add_edge(repo, user)\n",
        "        except:\n",
        "            pass\n",
        "        ix += 1"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nx.draw(network_no_weight, pos=nx.kamada_kawai_layout(network_no_weight, scale=10), with_labels=False)\n",
        "plt.axis('off')\n",
        "plt.rcParams[\"figure.figsize\"] = (20,20) # new\n",
        "plt.savefig(FIGURES_PATH + 'network_no_weight.png', bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " # TODO: Analysis Approach\n",
        "### RUBRIC: Approach (20%)\n",
        "\n",
        " - [ ] The approach is an appropriate method to take to solve the problem or answer the analytical question. \n",
        " - [ ] Approach taken goes beyond using the tools provided in class. \n",
        " - [ ] Team justifies and explains their approach well. Approach includes data collected and techniques used.\n",
        "\n",
        " ## TODO: Describe what analysis you performed to answer the questions\n",
        " ## TODO: What type of sentiment analysis did you do?  Briefly explain your rationale for doing it as such.\n",
        " ## TODO: What type of topic modelling did you do?  Again, briefly explain your rationale for your approach.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### RUBRIC: Analysis/result & Discussion (20%)\n",
        "\n",
        " - [ ] Problem solving: The solution solves the problem well and all the success criteria are satisfied. \n",
        " - [ ] Team is able to provide analytical and/or empirical evidence of this.\n",
        " - [ ] Answering analytical question & Analysis component: \n",
        "   - [ ] Excellent discussion of results that answers the question proposed \n",
        "     - [ ] or contributes towards solving the problem. \n",
        "   - [ ] Conclusions are supported by analytical and/or empirical evidence. \n",
        "   - [ ] All success criteria are answered.\n",
        " \n",
        " # TODO: Analysis & Insights\n",
        " ## TODO: Present your analysis, to answer the questions \n",
        " ## TODO: Present and discuss your insights\n",
        " ## TODO: Use plots, tables, example of prints, visualisation, word clouds etc that supports your analysis and insights\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#  Conclusion\n",
        "##  Provide a short conclusion about your entity, analysis and what you found\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Team Management & Mentoring\n",
        "\n",
        "- [ ] Use timesheets\n",
        "- [ ] Set up regular meetings within your team\n",
        "- [ ] We've setup a slack channel\n",
        "- [ ] [Github repo](https://github.com/tgrrr/data-science-social-network-analysis)\n",
        "- [ ] Meet lecturers 3 times before assignment due"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "argv": [
        "/Users/phil/.pyenv/versions/py36/bin/python3",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ],
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}